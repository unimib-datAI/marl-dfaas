{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Evaluation Summary Plots/Anaylisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Plots/Analysis for a single evaluation for a single experiment. For now, only the default evaluation is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports.\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib ipympl\n",
    "import base\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import dfaas_env\n",
    "import dfaas_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Global options for the notebook.\n",
    "\n",
    "* `exp_dir`: the full path for the experiment directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make this configurable.\n",
    "exp_dir = Path(\"/home/emanuele/marl-dfaas/results/DFAAS-MA_2024-12-20_11-49-29_500_SYN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Reward (all episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for average reward data.\n",
    "\n",
    "\n",
    "def _get_data(eval_dir):\n",
    "    data = {}\n",
    "\n",
    "    # Read data from the given evaluation directory\n",
    "    eval = dfaas_utils.parse_result_file(eval_dir / \"evaluation.json\")\n",
    "    eval = eval[0][\"env_runners\"]\n",
    "    agents = base.get_env(eval_dir).agents\n",
    "\n",
    "    data[\"agents\"] = agents\n",
    "    data[\"episodes\"] = eval[\"episodes_this_iter\"]\n",
    "\n",
    "    reward_total = {}  # Total reward per episode.\n",
    "    reward_total[\"all\"] = eval[\"hist_stats\"][\"episode_reward\"]\n",
    "    for agent in data[\"agents\"]:\n",
    "        reward_total[agent] = eval[\"hist_stats\"][f\"policy_policy_{agent}_reward\"]\n",
    "\n",
    "    data[\"reward_total_avg\"] = reward_total\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Get `data` and `env` variables, used by subsequents plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _get_data(exp_dir)\n",
    "env = base.get_env(exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Average reward per episode (all agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\")\n",
    "fig.canvas.header_visible = False\n",
    "ax = fig.subplots()\n",
    "\n",
    "# Limits for the y axis, both for total and single step.\n",
    "bottom, top = env.reward_range\n",
    "bottom_total = bottom * env.max_steps\n",
    "top_total = top * env.max_steps\n",
    "\n",
    "# First line: theoretical limit of reward.\n",
    "ax.plot(np.full(data[\"episodes\"], top_total * len(data[\"agents\"])), color=\"r\", label=\"Limit\")\n",
    "\n",
    "# Second line: real reward.\n",
    "ax.plot(data[\"reward_total_avg\"][\"all\"], label=\"Reward\")\n",
    "ax.set_ylim(bottom=bottom_total, top=top_total * len(data[\"agents\"])+10)\n",
    "ax.set_title(\"Average reward per episode (all agents)\")\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "\n",
    "ax.set_ylabel(\"Reward per episode\")\n",
    "\n",
    "ax.set_xlabel(\"Episode\")\n",
    "ax.xaxis.set_major_locator(\n",
    "    ticker.MultipleLocator(10)\n",
    ")  # Show x-axis ticks every 10 episodes.\n",
    "\n",
    "ax.grid(axis=\"both\")\n",
    "ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Average reward per episode (single agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in data[\"agents\"]:\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "    \n",
    "    # Limits for the y axis, both for total and single step.\n",
    "    bottom, top = env.reward_range\n",
    "    bottom_total = bottom * env.max_steps\n",
    "    top_total = top * env.max_steps\n",
    "\n",
    "    # First line: theoretical limit of reward.\n",
    "    ax.plot(np.full(data[\"episodes\"], top_total), color=\"r\", label=\"Limit\")\n",
    "    \n",
    "    # Second line: real reward.\n",
    "    ax.plot(data[\"reward_total_avg\"][agent], label=\"Reward\")\n",
    "    ax.set_ylim(bottom=bottom_total, top=top_total+10)\n",
    "    ax.set_title(f\"Average reward per episode ({agent = })\")\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "    \n",
    "    ax.set_ylabel(\"Reward per episode\")\n",
    "    \n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.xaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(10)\n",
    "    )  # Show x-axis ticks every 10 episodes.\n",
    "    \n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Queue size (single episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions to get data.\n",
    "\n",
    "def _get_data(eval_dir):\n",
    "    # Read data from the given evaluation directory\n",
    "    eval = dfaas_utils.parse_result_file(eval_dir / \"evaluation.json\")\n",
    "    eval = eval[0][\"env_runners\"]\n",
    "    agents = base.get_env(eval_dir).agents\n",
    "\n",
    "    data = {}\n",
    "    data[\"agents\"] = agents\n",
    "    data[\"queue_size\"] = eval[\"hist_stats\"][\"queue_size\"]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and env variables, used by the subsequent code.\n",
    "data = _get_data(exp_dir)\n",
    "env = base.get_env(exp_dir)\n",
    "episode_idx = 0  # Which episode to show in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in data[\"agents\"]:\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    ax.set_title(f\"Queue status for {agent = } and {episode_idx = }\")\n",
    "    ax.plot(data[\"queue_size\"][episode_idx][agent], label=\"Requests in queue\")\n",
    "    ax.plot(np.full(env.max_steps, env.queue_capacity), color=\"r\", label=\"Queue capacity\")\n",
    "    \n",
    "    ax.set_ylim(bottom=bottom, top=env.queue_capacity+10)  # Limits for the y axis.\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "    \n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    \n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.xaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(25)\n",
    "    )  # Show x-axis ticks every 25 steps.\n",
    "    \n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Show legend outside the plot at the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Processed requests (single episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data(eval_dir, episode_idx):\n",
    "    # Read data from the given evaluation directory\n",
    "    eval = dfaas_utils.parse_result_file(eval_dir / \"evaluation.json\")\n",
    "    eval = eval[0][\"env_runners\"]\n",
    "    agents = base.get_env(eval_dir).agents\n",
    "\n",
    "    data = {}\n",
    "    data[\"agents\"] = agents\n",
    "\n",
    "    # We must convert list to numpy arrays to allow array manipulation.\n",
    "    data[\"processed_local\"] = {}\n",
    "    data[\"processed_local_forward\"] = {}\n",
    "    for agent in agents:\n",
    "        data[\"processed_local\"][agent] = np.array(eval[\"hist_stats\"][\"processed_local\"][episode_idx][agent])\n",
    "        data[\"processed_local_forward\"][agent] = np.array(eval[\"hist_stats\"][\"processed_local_forward\"][episode_idx][agent])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and env variables, used by the subsequent code.\n",
    "episode_idx = 0  # Which episode to show in the plots.\n",
    "data = _get_data(exp_dir, episode_idx)\n",
    "env = base.get_env(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in data[\"agents\"]:\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    steps_x = np.arange(stop=env.max_steps)\n",
    "\n",
    "    ax.set_title(f\"Processed requests for {agent = } and {episode_idx = }\")\n",
    "    ax.bar(x=steps_x,\n",
    "           height=data[\"processed_local\"][agent] - data[\"processed_local_forward\"][agent],\n",
    "           color=\"g\",\n",
    "           label=\"Processed requests (local)\")\n",
    "    ax.bar(x=steps_x,\n",
    "           height=data[\"processed_local_forward\"][agent],\n",
    "           bottom=data[\"processed_local\"][agent] - data[\"processed_local_forward\"][agent],\n",
    "           color=\"b\",\n",
    "           label=\"Processed requests (forwarded)\")\n",
    "    \n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    \n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.xaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(25)\n",
    "    )  # Show x-axis ticks every 25 steps.\n",
    "    \n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Action (single episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data(eval_dir, episode_idx):\n",
    "    # Read data from the given evaluation directory\n",
    "    eval = dfaas_utils.parse_result_file(eval_dir / \"evaluation.json\")\n",
    "    eval = eval[0][\"env_runners\"]\n",
    "    agents = base.get_env(eval_dir).agents\n",
    "\n",
    "    data = {}\n",
    "    data[\"agents\"] = agents\n",
    "\n",
    "    # We must convert list to numpy arrays to allow array manipulation.\n",
    "    data[\"action_local\"] = {}\n",
    "    data[\"action_forward\"] = {}\n",
    "    data[\"action_reject\"] = {}\n",
    "    for agent in agents:\n",
    "        data[\"action_local\"][agent] = np.array(eval[\"hist_stats\"][\"action_local\"][episode_idx][agent])\n",
    "        data[\"action_forward\"][agent] = np.array(eval[\"hist_stats\"][\"action_forward\"][episode_idx][agent])\n",
    "        data[\"action_reject\"][agent] = np.array(eval[\"hist_stats\"][\"action_reject\"][episode_idx][agent])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and env variables, used by the subsequent code.\n",
    "episode_idx = 0  # Which episode to show in the plots.\n",
    "data = _get_data(exp_dir, episode_idx)\n",
    "env = base.get_env(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in data[\"agents\"]:\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    steps_x = np.arange(stop=env.max_steps)\n",
    "\n",
    "    ax.set_title(f\"Actions for {agent = } and {episode_idx = }\")\n",
    "    ax.bar(x=steps_x,\n",
    "           height=data[\"action_local\"][agent],\n",
    "           color=\"g\",\n",
    "           label=\"Local\")\n",
    "    ax.bar(x=steps_x,\n",
    "           height=data[\"action_forward\"][agent],\n",
    "           bottom=data[\"action_local\"][agent],\n",
    "           color=\"b\",\n",
    "           label=\"Forward\")\n",
    "    ax.bar(x=steps_x,\n",
    "           height=data[\"action_reject\"][agent],\n",
    "           bottom=data[\"action_local\"][agent] + data[\"action_forward\"][agent],\n",
    "           color=\"r\",\n",
    "           label=\"Reject\")\n",
    "\n",
    "    input_requests = data[\"action_local\"][agent] + data[\"action_forward\"][agent] + data[\"action_reject\"][agent]\n",
    "    ax.plot(input_requests, label=\"Input requests\")\n",
    "    \n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    \n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.xaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(25)\n",
    "    )  # Show x-axis ticks every 25 steps.\n",
    "    \n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "    ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
