# This Python script is expected to be imported by all Marimo notebooks.
from pathlib import Path
import logging
import sys
import os
import warnings

import numpy as np

import cloudpickle

import matplotlib

# Add the parent directory (the root directory of the project) to sys.path. This
# is needed to load modules like dfaas_utils or dfaas_env.
sys.path.append(Path(os.getcwd()).as_posix())

import dfaas_env
import dfaas_upperbound
import dfaas_utils

# Reset the matplotlib logger to warning, because Ray (called by dfaas_env
# module) changes the level to debug.
_matplotlib_logger = logging.root.manager.loggerDict["matplotlib"]
_matplotlib_logger.setLevel("WARNING")

# Initialize logger for this module.
logger = logging.getLogger(Path(__file__).name)
logger.setLevel(logging.DEBUG)
handler = logging.StreamHandler()
formatter = logging.Formatter("%(asctime)s %(levelname)s %(filename)s:%(lineno)d -- %(message)s")
handler.setFormatter(formatter)
logger.addHandler(handler)

# Set by default INFO level for root logger.
logging.getLogger().setLevel(logging.INFO)

# Convert NumPy warning to errors.
np.seterr(all="raise")

# This module-level variable holds the environment object. Supports multiple
# experiments (the key is the experiment path, value is the object).
_env = dict()

# Same as _env but for experiment configs (SACConfig, PPOConfig...).
_exp_config = dict()


def _env_init(exp_dir):
    """Initializes the internal _env variable by creating the environment with
    the configuration extracted from the given experiment directory."""
    if not exp_dir.exists():
        logger.critical(f"Experiment directory not found: {exp_dir.as_posix()!r}")
        raise FileNotFoundError(exp_dir)

    # Experiment configuration (read the existing one).
    exp_config = dfaas_utils.json_to_dict(exp_dir / "exp_config.json")

    # Environment configuration (read the existing one).
    env_config = dfaas_utils.json_to_dict(exp_dir / "env_config.json")

    # Create the environment with the given env config.
    global _env
    match exp_config["env"]:
        case "DFaaS":
            _env[exp_dir] = dfaas_env.DFaaS(config=env_config)
        case "SingleDFaaS":
            _env[exp_dir] = dfaas_upperbound.SingleDFaaS(config=env_config)
        case _:
            logger.critical(f"Unsupported environment for exp: {exp_dir.as_posix()!r}")
            raise ValueError(exp_dir)


def get_env(exp_dir):
    """Returns the environment from the given experiment directory."""
    if exp_dir not in _env:
        _env_init(exp_dir)

    return _env[exp_dir]


def _exp_config_init(exp_dir):
    """Initializes the internal _exp_config variable by creating the experiment
    config from the given experiment directory ("params.pkl" file)."""
    if not exp_dir.exists():
        logger.critical(f"Experiment directory not found: {exp_dir.as_posix()!r}")
        raise FileNotFoundError(exp_dir)

    # Deserialize the params.pkl file. This file is generated by RLlib when
    # running an experiment.
    params_file = exp_dir / "params.pkl"
    with params_file.open("rb") as params:
        config = cloudpickle.load(params)

    # Save the configuration to the global-level cache.
    global _exp_config
    _exp_config[exp_dir] = config


def get_exp_config(exp_dir):
    """Returns the experiment config (PPOConfig, SACConfig...) from the given
    experiment directory."""
    if exp_dir not in _exp_config:
        _exp_config_init(exp_dir)

    return _exp_config[exp_dir]


# We have large notebooks with more than 20 plots, do not show the default warning.
matplotlib.rcParams["figure.max_open_warning"] = 50

# Disable Ray's warnings.
warnings.filterwarnings("ignore", category=DeprecationWarning)


def get_experiments(exp_prefix):
    """Searches for experiment directories under the given exp_prefix
    directory (preferably a Path object, but can also be a string) and
    returns a list of tuples (experiment name and experiment path)."""
    # Force to have a Path object.
    if not isinstance(exp_prefix, Path):
        exp_prefix = Path(exp_prefix)

    # Scan the files and directories under exp_prefix.
    exps = []
    for exp in exp_prefix.iterdir():
        if (exp / "exp_config.json").exists():  # A single experiment.
            exps.append((exp.name, exp))
            continue

        # The experiment is a directory with sub-experiments, add
        # each experiment individually.
        for sub_exp in exp.iterdir():
            if (sub_exp / "exp_config.json").exists():  # A single experiment.
                exps.append((f"{exp.name}/{sub_exp.name}", sub_exp))

    # Newest experiment first.
    return sorted(exps, reverse=True)


def get_figure(name):
    matplotlib.pyplot.close(fig=name)
    fig = matplotlib.pyplot.figure(num=name, layout="constrained")
    fig.canvas.header_visible = False
    return fig


def get_moving_average(data, window_size=50):
    """Returns the moving average for a sequence of data points.

    For each index i, the average is computed over the previous `window_size`
    points, or all available points if fewer than `window_size` are present.

    Args:
        data (array-like): Sequence of numeric values to average.
        window_size (int): The size of the moving window.

    Returns:
        np.ndarray: Array of moving averages with the same length as `data`.
        int: The used moving window size.
    """
    assert len(data) > 0, "'data' must be at least of length 1"

    moving_avg = np.empty(len(data))
    for i in range(len(data)):
        start = max(0, i - window_size + 1)
        moving_avg[i] = np.mean(data[start : i + 1])

    return moving_avg, window_size
