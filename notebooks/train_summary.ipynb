{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Train Summary Plots/Anaylisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports.\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib widget\n",
    "import base\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import ipywidgets\n",
    "\n",
    "import dfaas_env\n",
    "import dfaas_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Select one or more experiments to view.\n",
    "\n",
    "**WARNING**: If multiple experiments are selected, they must share the same number of training iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = base.get_experiments(\"/home/emanuele/marl-dfaas/results\")\n",
    "\n",
    "# Show the name as the portion of the path after \"results\",\n",
    "# but anyway the values are full Path objects.\n",
    "exp_select = ipywidgets.SelectMultiple(\n",
    "    options=experiments,\n",
    "    index=[0],\n",
    "    description=\"Experiment(s):\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=ipywidgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "ipywidgets.AppLayout(center=exp_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Experiment selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "This section must be run before any of the following sections to load the selected experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = exp_select.value\n",
    "assert len(exps_dir) > 0, \"must select at least one experiment\"\n",
    "\n",
    "# Preload the data (result.json file) for all selected experiments.\n",
    "raw_exp_data = {}\n",
    "for exp_dir in exps_dir:\n",
    "    raw_exp_data[exp_dir] = dfaas_utils.parse_result_file(exp_dir / \"result.json\")\n",
    "\n",
    "# Create the reference environment.\n",
    "env = base.get_env(exps_dir[0])\n",
    "\n",
    "print(\"Selected experiments:\")\n",
    "for exp_dir in exps_dir:\n",
    "    print(f\"  - {exp_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for average reward data.\n",
    "\n",
    "\n",
    "def _average_reward_step(iter, agent):\n",
    "    \"\"\"Returns the average reward per step for the given iteration and agent.\"\"\"\n",
    "    episodes = iter[\"env_runners\"][\"episodes_this_iter\"]\n",
    "\n",
    "    tmp = np.empty(episodes, dtype=np.float32)\n",
    "    for epi_idx in range(episodes):\n",
    "        tmp[epi_idx] = np.average(\n",
    "            iter[\"env_runners\"][\"hist_stats\"][\"reward\"][epi_idx][agent]\n",
    "        )\n",
    "\n",
    "    return np.average(tmp)\n",
    "\n",
    "\n",
    "def _get_data(iter_data):\n",
    "    final_data = {}\n",
    "\n",
    "    for exp_dir, iters in iter_data.items():\n",
    "        data = {}\n",
    "        agents = base.get_env(exp_dir).agents\n",
    "\n",
    "        data[\"agents\"] = agents\n",
    "        data[\"iterations\"] = len(iters)\n",
    "        data[\"episodes\"] = iters[0][\"env_runners\"][\"episodes_this_iter\"]\n",
    "\n",
    "        reward_total_avg = {}  # Average total reward per episode.\n",
    "        reward_step_avg = {}  # Average reward per step.\n",
    "\n",
    "        reward_total_avg[\"all\"] = np.empty(data[\"iterations\"], dtype=np.float32)\n",
    "        for agent in data[\"agents\"]:\n",
    "            reward_total_avg[agent] = np.empty(data[\"iterations\"], dtype=np.float32)\n",
    "            reward_step_avg[agent] = np.empty(data[\"iterations\"], dtype=np.float32)\n",
    "\n",
    "        # For each iteration, get the average reward, since there are multiple\n",
    "        # episodes played in each iteration.\n",
    "        for iter in iters:\n",
    "            # Index starts from one in log files, but Python list from zero.\n",
    "            iter_idx = iter[\"training_iteration\"] - 1\n",
    "\n",
    "            reward_total_avg[\"all\"][iter_idx] = np.average(\n",
    "                iter[\"env_runners\"][\"hist_stats\"][\"episode_reward\"]\n",
    "            )\n",
    "\n",
    "            for agent in data[\"agents\"]:\n",
    "                reward_total_avg[agent][iter_idx] = np.average(\n",
    "                    iter[\"env_runners\"][\"hist_stats\"][f\"policy_policy_{agent}_reward\"]\n",
    "                )\n",
    "                reward_step_avg[agent][iter_idx] = _average_reward_step(iter, agent)\n",
    "\n",
    "        data[\"reward_total_avg\"] = reward_total_avg\n",
    "        data[\"reward_step_avg\"] = reward_step_avg\n",
    "\n",
    "        final_data[exp_dir] = data\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Get the specific `data` to be plotted in the following plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _get_data(raw_exp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Average per episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### All agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\")\n",
    "fig.canvas.header_visible = False\n",
    "ax = fig.subplots()\n",
    "\n",
    "# Limits for the y axis, both for total and single step.\n",
    "bottom, top = env.reward_range\n",
    "# bottom_total = bottom * env.max_steps\n",
    "# top_total = top * env.max_steps\n",
    "\n",
    "for exp_dir in exps_dir:\n",
    "    ax.plot(data[exp_dir][\"reward_total_avg\"][\"all\"], label=exp_dir.name)\n",
    "\n",
    "# ax.set_ylim(bottom=0, top=env.max_steps*len(env.agents))\n",
    "ax.set_title(\"Average reward per episode (all agents)\")\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "\n",
    "ax.set_ylabel(\"Reward per episode\")\n",
    "\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.xaxis.set_major_locator(\n",
    "    ticker.MultipleLocator(50)\n",
    ")  # Show x-axis ticks every 50 iterations.\n",
    "\n",
    "ax.legend(loc=\"lower center\")\n",
    "ax.grid(axis=\"both\")\n",
    "ax.set_axisbelow(True)  # By default the axis is over the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Single agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Limits for the y axis, both for total and single step.\n",
    "bottom, top = env.reward_range\n",
    "bottom_total = bottom * env.max_steps\n",
    "top_total = top * env.max_steps\n",
    "\n",
    "for agent in env.agents:\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    for exp_dir in exps_dir:\n",
    "        ax.plot(data[exp_dir][\"reward_total_avg\"][agent], label=exp_dir.name)\n",
    "\n",
    "    ax.set_ylim(bottom=bottom_total, top=top_total)\n",
    "    ax.set_title(f\"Average reward per episode ({agent = })\")\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "\n",
    "    ax.set_ylabel(\"Reward per episode\")\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.xaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(50)\n",
    "    )  # Show x-axis ticks every 50 iterations.\n",
    "\n",
    "    ax.legend(loc=\"lower center\")\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Processed requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for processed requests.\n",
    "\n",
    "\n",
    "def _get_data_episode(iter_data, epi_idx, env):\n",
    "    iter_data = iter_data[\"env_runners\"][\"hist_stats\"]\n",
    "\n",
    "    data = defaultdict(lambda: defaultdict())\n",
    "    (\n",
    "        data[\"all\"][\"processed_reqs\"],\n",
    "        data[\"all\"][\"input_reqs\"],\n",
    "        data[\"all\"][\"processed_forwarded_reqs\"],\n",
    "    ) = (0, 0, 0)\n",
    "    for agent in env.agents:\n",
    "        processed_reqs = np.sum(iter_data[\"processed_local\"][epi_idx][agent])\n",
    "        input_reqs = np.sum(iter_data[\"observation_input_requests\"][epi_idx][agent])\n",
    "        processed_forward = np.sum(iter_data[\"processed_local_forward\"][epi_idx][agent])\n",
    "\n",
    "        data[agent][\"processed_reqs\"] = processed_reqs\n",
    "        data[agent][\"input_reqs\"] = input_reqs\n",
    "        data[agent][\"processed_forwarded_reqs\"] = processed_forward\n",
    "        data[\"all\"][\"processed_reqs\"] += processed_reqs\n",
    "        data[\"all\"][\"input_reqs\"] += input_reqs\n",
    "        data[\"all\"][\"processed_forwarded_reqs\"] += processed_forward\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def _get_data(iter_data):\n",
    "    #  is a disctionary with three levels of depth (experiment, iteration, metrics).\n",
    "    final_data = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "\n",
    "    for exp_dir, iters in iter_data.items():\n",
    "        agents = base.get_env(exp_dir).agents\n",
    "        iterations = len(iters)\n",
    "\n",
    "        # Create the portion of the dictionary for this experiment that\n",
    "        # contains the average values of the metrics for each iteration.\n",
    "        for agent in [\"all\"] + env.agents:\n",
    "            for key in [\"input_reqs\", \"processed_reqs\", \"processed_forwarded_reqs\"]:\n",
    "                final_data[exp_dir][agent][key] = np.empty(iterations)\n",
    "\n",
    "        # For each iteration, calculate the metrics for each episode played,\n",
    "        # then average the values for the number of episodes of that iteration.\n",
    "        for iter_idx in range(iterations):\n",
    "            episodes = iters[iter_idx][\"env_runners\"][\"episodes_this_iter\"]\n",
    "\n",
    "            # Create the data dictionary that contains the metrics for each\n",
    "            # episode in this iteration.\n",
    "            data = defaultdict(lambda: defaultdict())\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                for key in [\"input_reqs\", \"processed_reqs\", \"processed_forwarded_reqs\"]:\n",
    "                    data[agent][key] = np.empty(episodes, dtype=np.int32)\n",
    "\n",
    "            # Iterate the episodes.\n",
    "            for epi_idx in range(episodes):\n",
    "                data_epi = _get_data_episode(iters[iter_idx], epi_idx, env)\n",
    "\n",
    "                for agent in [\"all\"] + env.agents:\n",
    "                    for key in [\n",
    "                        \"input_reqs\",\n",
    "                        \"processed_reqs\",\n",
    "                        \"processed_forwarded_reqs\",\n",
    "                    ]:\n",
    "                        data[agent][key][epi_idx] = data_epi[agent][key]\n",
    "\n",
    "            # Update iteration data.\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                for key in [\"input_reqs\", \"processed_reqs\", \"processed_forwarded_reqs\"]:\n",
    "                    final_data[exp_dir][agent][key][iter_idx] = np.average(\n",
    "                        data[agent][key]\n",
    "                    )\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Get the specific `data` to be plotted in the following plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _get_data(raw_exp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Average processed requests per episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### All agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\")\n",
    "fig.canvas.header_visible = False\n",
    "ax = fig.subplots()\n",
    "\n",
    "for exp_dir in exps_dir:\n",
    "    ratios = data[exp_dir][\"all\"][\"processed_reqs\"] / data[exp_dir][\"all\"][\"input_reqs\"]\n",
    "    ratios_forwarded = (\n",
    "        data[exp_dir][\"all\"][\"processed_forwarded_reqs\"]\n",
    "        / data[exp_dir][\"all\"][\"processed_reqs\"]\n",
    "    )\n",
    "\n",
    "    ax.plot(ratios, label=exp_dir.name)\n",
    "\n",
    "ax.set_title(\"Average processed requests per episode (all agents)\")\n",
    "\n",
    "ax.set_ylabel(\"Requests\")\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "ax.legend(loc=\"lower center\")\n",
    "ax.grid(axis=\"both\")\n",
    "ax.set_axisbelow(True)  # By default the axis is over the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Single agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in env.agents:\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    for exp_dir in exps_dir:\n",
    "        ratios = (\n",
    "            data[exp_dir][agent][\"processed_reqs\"] / data[exp_dir][agent][\"input_reqs\"]\n",
    "        )\n",
    "        # ratios_forwarded = data[exp_dir][agent][\"processed_forwarded_reqs\"] / data[exp_dir][\"all\"][\"processed_reqs\"]\n",
    "\n",
    "        ax.plot(ratios, label=exp_dir.name)\n",
    "\n",
    "    ax.set_title(f\"Average processed requests per episode ({agent = })\")\n",
    "\n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    ax.legend(loc=\"lower center\")\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Average processed forwarded requests per episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### All agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\")\n",
    "fig.canvas.header_visible = False\n",
    "ax = fig.subplots()\n",
    "\n",
    "for exp_dir in exps_dir:\n",
    "    ratios_forwarded = (\n",
    "        data[exp_dir][\"all\"][\"processed_forwarded_reqs\"]\n",
    "        / data[exp_dir][\"all\"][\"processed_reqs\"]\n",
    "    )\n",
    "\n",
    "    ax.plot(ratios_forwarded, label=exp_dir.name)\n",
    "\n",
    "ax.set_title(\"Average processed forwarded requests per episode (all agents)\")\n",
    "\n",
    "ax.set_ylabel(\"Requests\")\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "ax.legend(loc=\"lower center\")\n",
    "ax.grid(axis=\"both\")\n",
    "ax.set_axisbelow(True)  # By default the axis is over the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### Single agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in env.agents:\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    for exp_dir in exps_dir:\n",
    "        ratios_forwarded = (\n",
    "            data[exp_dir][agent][\"processed_forwarded_reqs\"]\n",
    "            / data[exp_dir][agent][\"processed_reqs\"]\n",
    "        )\n",
    "\n",
    "        ax.plot(ratios_forwarded, label=exp_dir.name)\n",
    "\n",
    "    ax.set_title(f\"Average processed forwarded requests per episode ({agent = })\")\n",
    "\n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    ax.legend(loc=\"lower center\")\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "To show some plots about the queue of agents, we first need to collect the data. Note that since this notebook is for summarised training for all iterations, the plots are an average of all episodes in an iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for queue.\n",
    "\n",
    "\n",
    "def _get_data(iter_data):\n",
    "    #  is a disctionary with three levels of depth (experiment, iteration, metrics).\n",
    "    final_data = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "\n",
    "    for exp_dir, iters in iter_data.items():\n",
    "        agents = base.get_env(exp_dir).agents\n",
    "        iterations = len(iters)\n",
    "\n",
    "        # Keys of the dictionary for each agent.\n",
    "        metrics = [\"queue_size_mean\", \"queue_size_std\"]\n",
    "\n",
    "        # Create the portion of the dictionary for this experiment that\n",
    "        # contains the average values of the metrics for each iteration.\n",
    "        for agent in [\"all\"] + env.agents:\n",
    "            for metric in metrics:\n",
    "                final_data[exp_dir][agent][metric] = np.empty(iterations)\n",
    "\n",
    "        # For each iteration, calculate the metrics for each episode played,\n",
    "        # then average the values for the number of episodes of that iteration.\n",
    "        for iter_idx in range(iterations):\n",
    "            episodes = iters[iter_idx][\"env_runners\"][\"episodes_this_iter\"]\n",
    "            hist_stats = iters[iter_idx][\"env_runners\"][\"hist_stats\"]\n",
    "\n",
    "            # Temporary dictionary for each iteration.\n",
    "            epi_data = defaultdict(lambda: defaultdict())\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                for metric in metrics:\n",
    "                    epi_data[agent][metric] = np.empty(episodes)\n",
    "\n",
    "            # Iterate the episodes.\n",
    "            for epi_idx in range(episodes):\n",
    "                queue_all = np.empty(0)\n",
    "\n",
    "                for agent in env.agents:\n",
    "                    queue = np.array(hist_stats[\"queue_size\"][epi_idx][agent])\n",
    "                    queue_all = np.concatenate([queue_all, queue])\n",
    "\n",
    "                    epi_data[agent][\"queue_size_mean\"][epi_idx] = np.mean(queue)\n",
    "                    epi_data[agent][\"queue_size_std\"][epi_idx] = np.std(queue)\n",
    "\n",
    "                epi_data[\"all\"][\"queue_size_mean\"][epi_idx] = np.mean(queue_all)\n",
    "                epi_data[\"all\"][\"queue_size_std\"][epi_idx] = np.std(queue_all)\n",
    "\n",
    "            # Update iteration data.\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                for metric in metrics:\n",
    "                    mean = np.mean(epi_data[agent][metric])\n",
    "                    final_data[exp_dir][agent][metric][iter_idx] = mean\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Get the specific `data` to be plotted in the following plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = _get_data(raw_exp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Average queue size per episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### All agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\")\n",
    "fig.canvas.header_visible = False\n",
    "ax = fig.subplots()\n",
    "\n",
    "for exp_dir in exps_dir:\n",
    "    ax.plot(\n",
    "        data[exp_dir][\"all\"][\"queue_size_mean\"] / env.queue_capacity, label=exp_dir.name\n",
    "    )\n",
    "\n",
    "ax.set_title(\"Average queue size per episode (all agents)\")\n",
    "\n",
    "ax.set_ylabel(\"Requests in queue\")\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "ax.legend(loc=\"lower center\")\n",
    "ax.grid(axis=\"both\")\n",
    "ax.set_axisbelow(True)  # By default the axis is over the content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### Single agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in env.agents:\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    for exp_dir in exps_dir:\n",
    "        ax.plot(\n",
    "            data[exp_dir][agent][\"queue_size_mean\"] / env.queue_capacity,\n",
    "            label=exp_dir.name,\n",
    "        )\n",
    "\n",
    "    ax.set_title(f\"Average queue size per episode ({agent = })\")\n",
    "\n",
    "    ax.set_ylabel(\"Requests in queue\")\n",
    "    ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    ax.legend(loc=\"lower center\")\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
