{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Train summary for a single episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook presents plots related to a single episode. It can display plots about an episode from two sources:\n",
    "\n",
    "1. **Training iterations**: each iteration plays the same number of episodes, but the episodes are different as they use randomly generated seeds.\n",
    "\n",
    "2. **Evaluation iterations**: each iteration also plays the same number of episodes, but they use the same list of seeds across iterations. This is to evaluate the agents over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Experiment loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports.\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib widget\n",
    "import base\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import dfaas_env\n",
    "import dfaas_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where the experiments are located..\n",
    "prefix_dir = Path(\"/home/emanuele/marl-dfaas/results/\")\n",
    "\n",
    "# Experiment directory.\n",
    "exp_dir = prefix_dir / \"DF_20250618_142445_PPO_linear_growth\"\n",
    "\n",
    "# Which training statistics to show: from training iterations or evaluation\n",
    "# iterations.\n",
    "mode = \"eval\"  # Or \"eval\"\n",
    "\n",
    "if mode == \"train\":\n",
    "    # The result file is a JSON with each entry separated by newline.\n",
    "    raw_exp_data = dfaas_utils.parse_result_file(exp_dir / \"result.json\")\n",
    "elif mode == \"eval\":\n",
    "    # The evaluation file is instead a normal JSON.\n",
    "    raw_exp_data = dfaas_utils.json_to_dict(exp_dir / \"evaluation.json\")\n",
    "else:\n",
    "    raise ValueError(f\"Invalid {mode = }\")\n",
    "\n",
    "# Reference environment.\n",
    "env = base.get_env(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Experiment prefix dir: {prefix_dir.as_posix()!r}\")\n",
    "print(f\"Experiment name:       {exp_dir.name!r}\")\n",
    "print(f\"Agents:                {env.agents} ({len(env.agents)})\")\n",
    "print(f\"Mode:                  {mode}\")\n",
    "if mode == \"train\":\n",
    "    print(f\"Iterations:            {len(raw_exp_data)}\")\n",
    "else:\n",
    "    print(f\"Evaluations:           {len(raw_exp_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which iteration (training or evaluation) to select?\n",
    "iteration_idx = 19\n",
    "\n",
    "# Which episode from the single iteration to select?\n",
    "episode_idx = 0\n",
    "\n",
    "assert 0 <= iteration_idx <= len(raw_exp_data) - 1, \"iteration_idx must be a valid iteration index!\"\n",
    "\n",
    "assert (\n",
    "    0 <= episode_idx < raw_exp_data[iteration_idx][\"env_runners\"][\"num_episodes\"]\n",
    "), \"episode_idx must be a valid episode index!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Selected iteration:    {iteration_idx}\")\n",
    "print(f\"Selected episode:      {episode_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reward_plot(raw_exp_data, env, iteration_idx, episode_idx):\n",
    "    for agent in [\"all\"] + env.agents:\n",
    "        plt.close(fig=f\"reward_{agent}\")\n",
    "        fig = plt.figure(num=f\"reward_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        if agent == \"all\":\n",
    "            reward = np.add(\n",
    "                *[\n",
    "                    raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"reward\"][episode_idx][agent]\n",
    "                    for agent in env.agents\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            reward = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"reward\"][episode_idx][agent]\n",
    "\n",
    "        ax.plot(reward)\n",
    "        ax.set_title(f\"Reward per step ({agent = })\")\n",
    "        ax.set_ylabel(\"Reward\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.2))\n",
    "\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "make_reward_plot(raw_exp_data, env, iteration_idx, episode_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Input rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_rate_plot(raw_exp_data, env, iteration_idx, episode_idx):\n",
    "    for agent in [\"all\"] + env.agents:\n",
    "        plt.close(fig=f\"input_rate_{agent}\")\n",
    "        fig = plt.figure(num=f\"input_rate_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        if agent == \"all\":\n",
    "            input_rate = np.add(\n",
    "                *[\n",
    "                    raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_rate\"][episode_idx][\n",
    "                        agent\n",
    "                    ]\n",
    "                    for agent in env.agents\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            input_rate = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_rate\"][\n",
    "                episode_idx\n",
    "            ][agent]\n",
    "\n",
    "        ax.plot(input_rate)\n",
    "        ax.set_title(f\"Input rate per step ({agent = })\")\n",
    "        ax.set_ylabel(\"Input rate\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "make_input_rate_plot(raw_exp_data, env, iteration_idx, episode_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Absolute Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_action(raw_exp_data, env, iteration_idx, episode_idx):\n",
    "    data = {}\n",
    "    for agent in env.agents:\n",
    "        data[agent] = {}\n",
    "        data[agent][\"input_rate\"] = np.array(\n",
    "            raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_rate\"][episode_idx][agent]\n",
    "        )\n",
    "        data[agent][\"action_local\"] = np.array(\n",
    "            raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_local\"][episode_idx][agent]\n",
    "        )\n",
    "        data[agent][\"action_forward\"] = np.array(\n",
    "            raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_forward\"][episode_idx][agent]\n",
    "        )\n",
    "        data[agent][\"action_reject\"] = np.array(\n",
    "            raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_reject\"][episode_idx][agent]\n",
    "        )\n",
    "\n",
    "        forward_reject = np.array(\n",
    "            raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"forward_reject_rate\"][episode_idx][agent]\n",
    "        )\n",
    "        local_reject = np.array(\n",
    "            raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"incoming_rate_local_reject\"][episode_idx][agent]\n",
    "        )\n",
    "        data[agent][\"reject_rate\"] = forward_reject + local_reject + data[agent][\"action_reject\"]\n",
    "\n",
    "    data[\"all\"] = {}\n",
    "    data[\"all\"][\"input_rate\"] = np.add(*[data[agent][\"input_rate\"] for agent in env.agents])\n",
    "    data[\"all\"][\"action_local\"] = np.add(*[data[agent][\"action_local\"] for agent in env.agents])\n",
    "    data[\"all\"][\"action_forward\"] = np.add(*[data[agent][\"action_forward\"] for agent in env.agents])\n",
    "    data[\"all\"][\"action_reject\"] = np.add(*[data[agent][\"action_reject\"] for agent in env.agents])\n",
    "    data[\"all\"][\"reject_rate\"] = np.add(*[data[agent][\"reject_rate\"] for agent in env.agents])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "absolute_action = get_absolute_action(raw_exp_data, env, iteration_idx, episode_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_absolute_action_plot(absolute_action):\n",
    "    for agent, agent_absolute_action in sorted(absolute_action.items()):\n",
    "        plt.close(fig=f\"absolute_action_{agent}\")\n",
    "        fig = plt.figure(num=f\"absolute_action_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        steps = np.arange(len(agent_absolute_action[\"input_rate\"]))\n",
    "\n",
    "        ax.plot(agent_absolute_action[\"input_rate\"], label=\"Input rate\")\n",
    "        ax.stackplot(\n",
    "            steps,\n",
    "            agent_absolute_action[\"action_local\"],\n",
    "            agent_absolute_action[\"action_forward\"],\n",
    "            agent_absolute_action[\"action_reject\"],\n",
    "            labels=[\"Action Local\", \"Action Forward\", \"Action Reject\"],\n",
    "            alpha=0.5,\n",
    "        )\n",
    "        ax.plot(agent_absolute_action[\"reject_rate\"], label=\"Reject rate\")\n",
    "\n",
    "        ax.set_title(f\"Action distribution per episode ({agent = })\")\n",
    "        ax.set_ylabel(\"Requests\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        # Use only integer ticks and let matplotlib to choose how many ticks to show.\n",
    "        # ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "        ax.legend()\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "\n",
    "\n",
    "make_absolute_action_plot(absolute_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_action_distribution_plot(raw_exp_data, env, iteration_idx, episode_idx):\n",
    "    for agent in [\"all\"] + env.agents:\n",
    "        plt.close(fig=f\"action_distribution_{agent}\")\n",
    "        fig = plt.figure(num=f\"action_distribution_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "\n",
    "    action_local_tmp, action_forward_tmp, action_reject_tmp = [], [], []\n",
    "    for agent in env.agents + [\"all\"]:\n",
    "        fig = plt.figure(num=f\"action_distribution_{agent}\")\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        steps = np.arange(env.max_steps)\n",
    "\n",
    "        if agent == \"all\":  # Always executed at the end.\n",
    "            # Sum all columns (one row for each agent).\n",
    "            action_local = np.array(action_local_tmp).sum(axis=0)\n",
    "            action_forward = np.array(action_forward_tmp).sum(axis=0)\n",
    "            action_reject = np.array(action_reject_tmp).sum(axis=0)\n",
    "        else:\n",
    "            action_local = np.array(\n",
    "                raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_local\"][episode_idx][agent]\n",
    "            )\n",
    "            action_forward = np.array(\n",
    "                raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_forward\"][episode_idx][agent]\n",
    "            )\n",
    "            action_reject = np.array(\n",
    "                raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_reject\"][episode_idx][agent]\n",
    "            )\n",
    "\n",
    "            action_local_tmp.append(action_local)\n",
    "            action_forward_tmp.append(action_forward)\n",
    "            action_reject_tmp.append(action_reject)\n",
    "\n",
    "        input_rate = action_local + action_forward + action_reject\n",
    "\n",
    "        # Convert to ratios, but make sure to avoid division by zero (when input_rate is zero).\n",
    "        action_local = np.divide(action_local, input_rate, out=np.zeros(env.max_steps), where=input_rate != 0) * 100\n",
    "        action_forward = np.divide(action_forward, input_rate, out=np.zeros(env.max_steps), where=input_rate != 0) * 100\n",
    "        action_reject = np.divide(action_reject, input_rate, out=np.zeros(env.max_steps), where=input_rate != 0) * 100\n",
    "\n",
    "        ax.stackplot(\n",
    "            steps, action_local, action_forward, action_reject, labels=[\"Local\", \"Forward\", \"Reject\"], alpha=0.8\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"Action distribution per step ({agent = })\")\n",
    "        ax.set_ylabel(\"Action\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        ax.yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax.legend()\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "episode_idx\n",
    "\n",
    "make_action_distribution_plot(raw_exp_data, env, iteration_idx, episode_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reject_rate_plot(raw_exp_data, env, iteration_idx):\n",
    "    for agent in [\"all\"] + env.agents:\n",
    "        plt.close(fig=f\"reject_rate_{agent}\")\n",
    "        fig = plt.figure(num=f\"reject_rate_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "\n",
    "    total_reject_tmp, input_rate_tmp = [], []\n",
    "    for agent in env.agents + [\"all\"]:\n",
    "        fig = plt.figure(num=f\"reject_rate_{agent}\")\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        if agent == \"all\":  # Always at the end.\n",
    "            # Sum all columns (one row for each agent).\n",
    "            input_rate = np.array(input_rate_tmp).sum(axis=0)\n",
    "            total_reject = np.array(total_reject_tmp).sum(axis=0)\n",
    "        else:\n",
    "            input_rate = np.array(\n",
    "                raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_requests\"][0][agent]\n",
    "            )\n",
    "            action_reject = np.array(\n",
    "                raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_reject\"][0][agent]\n",
    "            )\n",
    "            excess_local = np.array(\n",
    "                raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"incoming_rate_local_reject\"][0][agent]\n",
    "            )\n",
    "            excess_forward = np.array(\n",
    "                raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"forward_reject_rate\"][0][agent]\n",
    "            )\n",
    "            total_reject = action_reject + excess_local + excess_forward\n",
    "\n",
    "            total_reject_tmp.append(total_reject)\n",
    "            input_rate_tmp.append(input_rate)\n",
    "\n",
    "        # Convert to percentual.\n",
    "        total_reject = np.divide(total_reject, input_rate, out=np.zeros(env.max_steps), where=input_rate != 0) * 100\n",
    "\n",
    "        ax.plot(total_reject)\n",
    "\n",
    "        ax.set_title(f\"Reject rate¹ (as % over input rate) per step ({agent = })\")\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            -0.2,\n",
    "            \"¹reject rate = action reject + local reject + forward reject\",\n",
    "            fontsize=10,\n",
    "            ha=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "        )\n",
    "        ax.set_ylabel(\"Reject rate\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        ax.yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "make_reject_rate_plot(raw_exp_data, env, iteration_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## A single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in [174]:\n",
    "    print(f\"Iteration nr. {iteration_idx}  Step nr {step}\")\n",
    "    for agent in env.agents:\n",
    "        observation_input_rate = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_requests\"][\n",
    "            0\n",
    "        ][agent][step]\n",
    "        observation_prev_local_rate = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\n",
    "            \"observation_prev_local_requests\"\n",
    "        ][0][agent][step]\n",
    "        observation_prev_local_reject = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\n",
    "            \"observation_prev_local_rejects\"\n",
    "        ][0][agent][step]\n",
    "        observation_prev_forward_rate = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\n",
    "            \"observation_prev_forward_requests\"\n",
    "        ][0][agent][step]\n",
    "        observation_prev_forward_reject = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\n",
    "            \"observation_prev_forward_rejects\"\n",
    "        ][0][agent][step]\n",
    "\n",
    "        action_local = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_local\"][0][agent][step]\n",
    "        action_forward = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_forward\"][0][agent][step]\n",
    "        action_reject = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"action_reject\"][0][agent][step]\n",
    "\n",
    "        excess_local = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"incoming_rate_local_reject\"][0][agent][\n",
    "            step\n",
    "        ]\n",
    "\n",
    "        forward_reject = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"forward_reject_rate\"][0][agent][step]\n",
    "\n",
    "        reward = raw_exp_data[iteration_idx][\"env_runners\"][\"hist_stats\"][\"reward\"][0][agent][step]\n",
    "\n",
    "        print(f\"\\n--- Agent: {agent} ---\")\n",
    "        print(\"-- Observation\")\n",
    "        print(f\"Input rate:           {observation_input_rate:.1f}\")\n",
    "        print(f\"Prev. local rate:     {observation_prev_local_rate:.1f}\")\n",
    "        print(f\"Prev. local reject:   {observation_prev_local_reject:.1f}\")\n",
    "        print(f\"Prev. forward rate:   {observation_prev_forward_rate:.1f}\")\n",
    "        print(f\"Prev. forward reject: {observation_prev_forward_reject:.1f}\")\n",
    "\n",
    "        print(\"-- Action\")\n",
    "        print(f\"Local:   {action_local:.1f}\")\n",
    "        print(f\"Forward: {action_forward:.1f}\")\n",
    "        print(f\"Reject:  {action_reject:.1f}\")\n",
    "\n",
    "        print(\"-- Additional rejects\")\n",
    "        print(f\"Local reject rate:   {excess_local:.1f}\")\n",
    "        print(f\"Forward reject rate: {forward_reject:.1f}\")\n",
    "\n",
    "        print(f\"-- Reward: {reward:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
