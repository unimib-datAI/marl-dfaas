{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Train summary for a single episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook displays graphs and data about a single episode in the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Experiment loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports.\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib widget\n",
    "import base\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import ipywidgets\n",
    "\n",
    "import dfaas_env\n",
    "import dfaas_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dir = Path(\"/home/emanuele/marl-dfaas/results/\")\n",
    "\n",
    "exp_dir = prefix_dir / \"DFAAS-MA_2025-05-13_17-49-24_PPO_2_constant_rate_200_iters\"\n",
    "\n",
    "# Raw data dictionary \"result.json\".\n",
    "raw_exp_data = dfaas_utils.parse_result_file(exp_dir / \"result.json\")\n",
    "\n",
    "# Reference environment.\n",
    "env = base.get_env(exp_dir)\n",
    "\n",
    "agents = [\"all\"] + env.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_idx = 199\n",
    "assert 0 <= iter_idx <= len(raw_exp_data) - 1, \"iter_idx must be a valid iteration index!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Experiment prefix dir: {prefix_dir.as_posix()!r}\")\n",
    "print(f\"Experiment name:       {exp_dir.name!r}\")\n",
    "print(f\"Agents:                {env.agents} ({len(env.agents)})\")\n",
    "print(f\"Selected iteration:    {iter_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reward_plot(raw_exp_data, env, iter_idx):\n",
    "    for agent in [\"all\"] + env.agents:\n",
    "        plt.close(fig=f\"reward_cum_{agent}\")\n",
    "        fig = plt.figure(num=f\"reward_cum_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        if agent == \"all\":\n",
    "            reward = np.add(\n",
    "                *[raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"reward\"][0][agent] for agent in env.agents]\n",
    "            )\n",
    "        else:\n",
    "            reward = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"reward\"][0][agent]\n",
    "\n",
    "        ax.plot(reward)\n",
    "        ax.set_title(f\"Reward per step ({agent = })\")\n",
    "        ax.set_ylabel(\"Reward\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.2))\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "make_reward_plot(raw_exp_data, env, iter_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Input rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_rate_plot(raw_exp_data, env, iter_idx):\n",
    "    for agent in [\"all\"] + env.agents:\n",
    "        plt.close(fig=f\"input_rate_{agent}\")\n",
    "        fig = plt.figure(num=f\"input_rate_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        if agent == \"all\":\n",
    "            input_rate = np.add(\n",
    "                *[\n",
    "                    raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_requests\"][0][agent]\n",
    "                    for agent in env.agents\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            input_rate = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_requests\"][0][agent]\n",
    "\n",
    "        ax.plot(input_rate)\n",
    "        ax.set_title(f\"Input rate per step ({agent = })\")\n",
    "        ax.set_ylabel(\"Input rate\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "make_input_rate_plot(raw_exp_data, env, iter_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_action_distribution_plot(raw_exp_data, env, iter_idx):\n",
    "    for agent in [\"all\"] + env.agents:\n",
    "        plt.close(fig=f\"action_distribution_{agent}\")\n",
    "        fig = plt.figure(num=f\"action_distribution_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "\n",
    "    action_local_tmp, action_forward_tmp, action_reject_tmp = [], [], []\n",
    "    for agent in env.agents + [\"all\"]:\n",
    "        fig = plt.figure(num=f\"action_distribution_{agent}\")\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        steps = np.arange(env.max_steps)\n",
    "\n",
    "        if agent == \"all\":  # Always executed at the end.\n",
    "            # Sum all columns (one row for each agent).\n",
    "            action_local = np.array(action_local_tmp).sum(axis=0)\n",
    "            action_forward = np.array(action_forward_tmp).sum(axis=0)\n",
    "            action_reject = np.array(action_reject_tmp).sum(axis=0)\n",
    "        else:\n",
    "            action_local = np.array(raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"action_local\"][0][agent])\n",
    "            action_forward = np.array(raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"action_forward\"][0][agent])\n",
    "            action_reject = np.array(raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"action_reject\"][0][agent])\n",
    "\n",
    "            action_local_tmp.append(action_local)\n",
    "            action_forward_tmp.append(action_forward)\n",
    "            action_reject_tmp.append(action_reject)\n",
    "\n",
    "        input_rate = action_local + action_forward + action_reject\n",
    "\n",
    "        # Convert to ratios, but make sure to avoid division by zero (when input_rate is zero).\n",
    "        action_local = np.divide(action_local, input_rate, out=np.zeros(env.max_steps), where=input_rate != 0)\n",
    "        action_forward = np.divide(action_forward, input_rate, out=np.zeros(env.max_steps), where=input_rate != 0)\n",
    "        action_reject = np.divide(action_reject, input_rate, out=np.zeros(env.max_steps), where=input_rate != 0)\n",
    "\n",
    "        ax.stackplot(\n",
    "            steps, action_local, action_forward, action_reject, labels=[\"Local\", \"Forward\", \"Reject\"], alpha=0.8\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"Action distribution per step ({agent = })\")\n",
    "        ax.set_ylabel(\"Action\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax.legend()\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "make_action_distribution_plot(raw_exp_data, env, iter_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reject_rate_plot(raw_exp_data, env, iter_idx):\n",
    "    for agent in [\"all\"] + env.agents:\n",
    "        plt.close(fig=f\"reject_rate_{agent}\")\n",
    "        fig = plt.figure(num=f\"reject_rate_{agent}\", layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "\n",
    "    total_reject_tmp, input_rate_tmp = [], []\n",
    "    for agent in env.agents + [\"all\"]:\n",
    "        fig = plt.figure(num=f\"reject_rate_{agent}\")\n",
    "        ax = fig.subplots()\n",
    "\n",
    "        if agent == \"all\":  # Always at the end.\n",
    "            # Sum all columns (one row for each agent).\n",
    "            input_rate = np.array(input_rate_tmp).sum(axis=0)\n",
    "            total_reject = np.array(total_reject_tmp).sum(axis=0)\n",
    "        else:\n",
    "            input_rate = np.array(\n",
    "                raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_requests\"][0][agent]\n",
    "            )\n",
    "            action_reject = np.array(raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"action_reject\"][0][agent])\n",
    "            excess_local = np.array(\n",
    "                raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"incoming_rate_local_reject\"][0][agent]\n",
    "            )\n",
    "            excess_forward = np.array(\n",
    "                raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"forward_reject_rate\"][0][agent]\n",
    "            )\n",
    "            total_reject = action_reject + excess_local + excess_forward\n",
    "\n",
    "            total_reject_tmp.append(total_reject)\n",
    "            input_rate_tmp.append(input_rate)\n",
    "\n",
    "        # Convert to percentual.\n",
    "        total_reject = np.divide(total_reject, input_rate, out=np.zeros(env.max_steps), where=input_rate != 0) * 100\n",
    "\n",
    "        ax.plot(total_reject)\n",
    "\n",
    "        ax.set_title(f\"Reject rate¹ (as % over input rate) per step ({agent = })\")\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            -0.2,\n",
    "            \"¹reject rate = action reject + local reject + forward reject\",\n",
    "            fontsize=10,\n",
    "            ha=\"center\",\n",
    "            transform=ax.transAxes,\n",
    "        )\n",
    "        ax.set_ylabel(\"Reject rate\")\n",
    "        ax.set_xlabel(\"Step\")\n",
    "        ax.yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "        ax.grid(axis=\"both\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "make_reject_rate_plot(raw_exp_data, env, iter_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## A single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in [71]:\n",
    "    print(f\"Iteration nr. {iter_idx}  Step nr {step}\")\n",
    "    for agent in env.agents:\n",
    "        observation_input_rate = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"observation_input_requests\"][0][\n",
    "            agent\n",
    "        ][step]\n",
    "        observation_prev_local_rate = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\n",
    "            \"observation_prev_local_requests\"\n",
    "        ][0][agent][step]\n",
    "        observation_prev_local_reject = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\n",
    "            \"observation_prev_local_rejects\"\n",
    "        ][0][agent][step]\n",
    "        observation_prev_forward_rate = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\n",
    "            \"observation_prev_forward_requests\"\n",
    "        ][0][agent][step]\n",
    "        observation_prev_forward_reject = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\n",
    "            \"observation_prev_forward_rejects\"\n",
    "        ][0][agent][step]\n",
    "\n",
    "        action_local = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"action_local\"][0][agent][step]\n",
    "        action_forward = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"action_forward\"][0][agent][step]\n",
    "        action_reject = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"action_reject\"][0][agent][step]\n",
    "\n",
    "        excess_local = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"incoming_rate_local_reject\"][0][agent][step]\n",
    "\n",
    "        forward_reject = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"forward_reject_rate\"][0][agent][step]\n",
    "\n",
    "        reward = raw_exp_data[iter_idx][\"env_runners\"][\"hist_stats\"][\"reward\"][0][agent][step]\n",
    "\n",
    "        print(f\"\\n--- Agent: {agent} ---\")\n",
    "        print(\"-- Observation\")\n",
    "        print(f\"Input rate:           {observation_input_rate:.1f}\")\n",
    "        print(f\"Prev. local rate:     {observation_prev_local_rate:.1f}\")\n",
    "        print(f\"Prev. local reject:   {observation_prev_local_reject:.1f}\")\n",
    "        print(f\"Prev. forward rate:   {observation_prev_forward_rate:.1f}\")\n",
    "        print(f\"Prev. forward reject: {observation_prev_forward_reject:.1f}\")\n",
    "\n",
    "        print(\"-- Action\")\n",
    "        print(f\"Local:   {action_local:.1f}\")\n",
    "        print(f\"Forward: {action_forward:.1f}\")\n",
    "        print(f\"Reject:  {action_reject:.1f}\")\n",
    "\n",
    "        print(\"-- Additional rejects\")\n",
    "        print(f\"Local reject rate:   {excess_local:.1f}\")\n",
    "        print(f\"Forward reject rate: {forward_reject:.1f}\")\n",
    "\n",
    "        print(f\"-- Reward: {reward:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
