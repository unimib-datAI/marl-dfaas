{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PAISE 2025 Plots/Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports.\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib widget\n",
    "import base\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import ipywidgets\n",
    "\n",
    "import dfaas_env\n",
    "import dfaas_utils\n",
    "import dfaas_upperbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase font, fig sizes and DPI for plots.\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"figure.figsize\": [7.68, 5.76],  # Increased by 20% from the default [6.4, 4.8]\n",
    "        \"figure.dpi\": 150,  # Increase DPI value from the default (140)\n",
    "        \"font.size\": 15,  # Increase the default font size (12/11)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Experiment loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dir = Path(\"../results/paise2025_2\")\n",
    "\n",
    "exps_dir = []\n",
    "for exp in prefix_dir.iterdir():\n",
    "    exps_dir.append(exp)\n",
    "\n",
    "# DEBUG\n",
    "# exps_dir = [prefix_dir / \"DFAAS-MA_2025-02-13_02-11-18_PPO_45\"]\n",
    "\n",
    "assert len(exps_dir) > 0, \"must select at least one experiment\"\n",
    "\n",
    "# Preload the data (result.json file) for all selected experiments.\n",
    "raw_exp_data = {}\n",
    "for exp_dir in exps_dir:\n",
    "    raw_exp_data[exp_dir] = dfaas_utils.parse_result_file(exp_dir / \"result.json\")\n",
    "\n",
    "# Create the reference environment based on DFaaS.\n",
    "for exp_dir in exps_dir:\n",
    "    env = base.get_env(exp_dir)\n",
    "    if env.__class__ == dfaas_env.DFaaS:\n",
    "        break\n",
    "\n",
    "# At least one experiment must be of type DFaaS. SingleDFaaS is used only as\n",
    "# reference.\n",
    "assert env.__class__ == dfaas_env.DFaaS, f\"{env.__class__}\"\n",
    "\n",
    "print(\"Selected experiments:\")\n",
    "for exp_dir in exps_dir:\n",
    "    print(f\"  - {exp_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Enqueued requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for processed requests.\n",
    "\n",
    "\n",
    "def get_enqueued_requests_data_upperbound(iters):\n",
    "    iterations = len(iters)\n",
    "    final_data = {}\n",
    "    final_data[\"input_reqs_avg\"] = np.empty(iterations)\n",
    "    final_data[\"enqueued_reqs_local_avg\"] = np.empty(iterations)\n",
    "    final_data[\"enqueued_reqs_forward_avg\"] = np.empty(iterations)\n",
    "\n",
    "    # For each iteration, calculate the metrics for each episode played,\n",
    "    # then average the values for the number of episodes of that iteration.\n",
    "    for iter_idx in range(iterations):\n",
    "        episodes = iters[iter_idx][\"env_runners\"][\"episodes_this_iter\"]\n",
    "        iter_data = iters[iter_idx][\"env_runners\"][\"hist_stats\"]\n",
    "\n",
    "        # Create the data dictionary that contains the metrics for each\n",
    "        # episode in this iteration.\n",
    "        data = {}\n",
    "        data[\"input_reqs\"] = np.empty(episodes, dtype=np.int32)\n",
    "        data[\"enqueued_reqs_local\"] = np.empty(episodes, dtype=np.int32)\n",
    "        data[\"enqueued_reqs_forward\"] = np.empty(episodes, dtype=np.int32)\n",
    "\n",
    "        # Iterate the episodes.\n",
    "        for epi_idx in range(episodes):\n",
    "            input_reqs = np.sum(iter_data[\"observation_input_requests\"][epi_idx])\n",
    "\n",
    "            # Calculate local, queued, or directly processed requests. Note that the\n",
    "            # rejections must be subtracted!\n",
    "            local_reqs = np.array(iter_data[\"action_local\"][epi_idx])\n",
    "            local_rejects = np.array(iter_data[\"local_rejects_queue_full\"][epi_idx])\n",
    "            real_local_reqs = np.sum(local_reqs - local_rejects)\n",
    "\n",
    "            data[\"input_reqs\"][epi_idx] = input_reqs\n",
    "            data[\"enqueued_reqs_local\"][epi_idx] = real_local_reqs\n",
    "\n",
    "        # Update iteration data.\n",
    "        final_data[\"input_reqs_avg\"][iter_idx] = np.average(data[\"input_reqs\"])\n",
    "        final_data[\"enqueued_reqs_local_avg\"][iter_idx] = np.average(\n",
    "            data[\"enqueued_reqs_local\"]\n",
    "        )\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "def get_enqueued_requests_data(iter_data):\n",
    "    # (experiment, iteration, metrics).\n",
    "    final_data = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "\n",
    "    for exp_dir, iters in iter_data.items():\n",
    "        env = base.get_env(exp_dir)\n",
    "        if env.__class__ == dfaas_upperbound.SingleDFaaS:\n",
    "            # The GlobalNode data extraction is different from the normal flow.\n",
    "            final_data[exp_dir] = get_enqueued_requests_data_upperbound(iters)\n",
    "            continue\n",
    "\n",
    "        iterations = len(iters)\n",
    "\n",
    "        # Create the portion of the dictionary for this experiment that\n",
    "        # contains the average values of the metrics for each iteration.\n",
    "        for agent in [\"all\"] + env.agents:\n",
    "            final_data[exp_dir][agent][\"input_reqs_avg\"] = np.empty(iterations)\n",
    "            final_data[exp_dir][agent][\"enqueued_reqs_local_avg\"] = np.empty(iterations)\n",
    "            final_data[exp_dir][agent][\"enqueued_reqs_forward_avg\"] = np.empty(\n",
    "                iterations\n",
    "            )\n",
    "            final_data[exp_dir][agent][\"enqueued_reqs_reject_avg\"] = np.empty(\n",
    "                iterations\n",
    "            )\n",
    "\n",
    "        # For each iteration, calculate the metrics for each episode played,\n",
    "        # then average the values for the number of episodes of that iteration.\n",
    "        for iter_idx in range(iterations):\n",
    "            episodes = iters[iter_idx][\"env_runners\"][\"episodes_this_iter\"]\n",
    "            iter_data = iters[iter_idx][\"env_runners\"][\"hist_stats\"]\n",
    "\n",
    "            # Create the data dictionary that contains the metrics for each\n",
    "            # episode in this iteration.\n",
    "            data = defaultdict(lambda: defaultdict())\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                data[agent][\"input_reqs\"] = np.zeros(episodes, dtype=np.int32)\n",
    "                data[agent][\"enqueued_reqs_local\"] = np.zeros(episodes, dtype=np.int32)\n",
    "                data[agent][\"enqueued_reqs_forward\"] = np.zeros(\n",
    "                    episodes, dtype=np.int32\n",
    "                )\n",
    "                data[agent][\"enqueued_reqs_reject\"] = np.zeros(episodes, dtype=np.int32)\n",
    "\n",
    "            # Iterate the episodes.\n",
    "            for epi_idx in range(episodes):\n",
    "                for agent in env.agents:\n",
    "                    input_reqs = np.sum(\n",
    "                        iter_data[\"observation_input_requests\"][epi_idx][agent]\n",
    "                    )\n",
    "\n",
    "                    # Calculate local, queued, or directly processed requests. Note that the\n",
    "                    # rejections must be subtracted!\n",
    "                    local_reqs = np.array(iter_data[\"action_local\"][epi_idx][agent])\n",
    "                    local_rejects = np.array(\n",
    "                        iter_data[\"local_rejects_queue_full\"][epi_idx][agent]\n",
    "                    )\n",
    "                    real_local_reqs = np.sum(local_reqs - local_rejects)\n",
    "\n",
    "                    # Same for forwarded requests.\n",
    "                    forwarded_reqs = np.array(\n",
    "                        iter_data[\"action_forward\"][epi_idx][agent]\n",
    "                    )\n",
    "                    forwarded_rejects = np.array(\n",
    "                        iter_data[\"forward_rejects\"][epi_idx][agent]\n",
    "                    )\n",
    "                    real_forwarded_reqs = np.sum(forwarded_reqs - forwarded_rejects)\n",
    "\n",
    "                    rejected_reqs = np.array(iter_data[\"action_reject\"][epi_idx][agent])\n",
    "                    real_rejected_reqs = np.sum(\n",
    "                        rejected_reqs + local_rejects + forwarded_rejects\n",
    "                    )\n",
    "\n",
    "                    assert np.all(\n",
    "                        real_local_reqs + real_forwarded_reqs + real_rejected_reqs\n",
    "                        == input_reqs\n",
    "                    )\n",
    "\n",
    "                    data[agent][\"input_reqs\"][epi_idx] = input_reqs\n",
    "                    data[agent][\"enqueued_reqs_local\"][epi_idx] = real_local_reqs\n",
    "                    data[agent][\"enqueued_reqs_forward\"][epi_idx] = real_forwarded_reqs\n",
    "                    data[agent][\"enqueued_reqs_reject\"][epi_idx] = real_rejected_reqs\n",
    "                    data[\"all\"][\"input_reqs\"][epi_idx] += input_reqs\n",
    "                    data[\"all\"][\"enqueued_reqs_local\"][epi_idx] += real_local_reqs\n",
    "                    data[\"all\"][\"enqueued_reqs_forward\"][epi_idx] += real_forwarded_reqs\n",
    "                    data[\"all\"][\"enqueued_reqs_reject\"][epi_idx] += real_rejected_reqs\n",
    "\n",
    "            # Update iteration data.\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                final_data[exp_dir][agent][\"input_reqs_avg\"][iter_idx] = np.average(\n",
    "                    data[agent][\"input_reqs\"]\n",
    "                )\n",
    "                final_data[exp_dir][agent][\"enqueued_reqs_local_avg\"][iter_idx] = (\n",
    "                    np.average(data[agent][\"enqueued_reqs_local\"])\n",
    "                )\n",
    "                final_data[exp_dir][agent][\"enqueued_reqs_forward_avg\"][iter_idx] = (\n",
    "                    np.average(data[agent][\"enqueued_reqs_forward\"])\n",
    "                )\n",
    "                final_data[exp_dir][agent][\"enqueued_reqs_reject_avg\"][iter_idx] = (\n",
    "                    np.average(data[agent][\"enqueued_reqs_reject\"])\n",
    "                )\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "enqueued_reqs_data = get_enqueued_requests_data(raw_exp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess additional data.\n",
    "enqueued_reqs_data_avg = {\"SAC\": {}, \"PPO\": {}, \"APL\": {}, \"GlobalNode\": {}}\n",
    "algorithms = [\"SAC\", \"PPO\", \"APL\"]\n",
    "for algorithm in algorithms:\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms (and environment).\n",
    "        if algorithm in exp_dir.name and \"SingleDFaaS\" not in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "        continue\n",
    "\n",
    "    ratios = []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp = (\n",
    "            enqueued_reqs_data[exp][\"all\"][\"enqueued_reqs_local_avg\"]\n",
    "            + enqueued_reqs_data[exp][\"all\"][\"enqueued_reqs_forward_avg\"]\n",
    "        ) / enqueued_reqs_data[exp][\"all\"][\"input_reqs_avg\"]\n",
    "\n",
    "        ratios.append(ratios_single_exp)\n",
    "    ratios = np.array(ratios)\n",
    "\n",
    "    avg = np.average(ratios, axis=0)\n",
    "    std = np.std(ratios, axis=0)\n",
    "\n",
    "    enqueued_reqs_data_avg[algorithm][\"enqueued_reqs_ratios_avg\"] = avg\n",
    "    enqueued_reqs_data_avg[algorithm][\"enqueued_reqs_ratios_std\"] = std\n",
    "\n",
    "    print(f\"Algorithm {algorithm} done with {len(experiments)} experiments\")\n",
    "\n",
    "\n",
    "# GlobalNode case is special.\n",
    "def upperbound_enqueued_request():\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms and environment.\n",
    "        if \"SingleDFaaS\" in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(\"WARN: Skipping GlobalNode, no experiments found!\")\n",
    "        return\n",
    "\n",
    "    ratios = []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp = (\n",
    "            enqueued_reqs_data[exp][\"enqueued_reqs_local_avg\"]\n",
    "            / enqueued_reqs_data[exp][\"input_reqs_avg\"]\n",
    "        )\n",
    "\n",
    "        ratios.append(ratios_single_exp)\n",
    "    ratios = np.array(ratios)\n",
    "\n",
    "    avg = np.average(ratios, axis=0)\n",
    "    std = np.std(ratios, axis=0)\n",
    "\n",
    "    enqueued_reqs_data_avg[\"GlobalNode\"][\"enqueued_reqs_ratios_avg\"] = avg\n",
    "    enqueued_reqs_data_avg[\"GlobalNode\"][\"enqueued_reqs_ratios_std\"] = std\n",
    "\n",
    "    print(f\"GlobalNode done with {len(experiments)} experiments\")\n",
    "\n",
    "\n",
    "upperbound_enqueued_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Average enqueued requests per episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### All agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_avg_enqueued_reqs_plot_all_agents():\n",
    "    plt.close(fig=\"avg_enqueued_reqs_all_agents\")\n",
    "    fig = plt.figure(num=\"avg_enqueued_reqs_all_agents\", layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    iteration_coords_x = np.linspace(start=1, stop=300, num=300)\n",
    "\n",
    "    for algorithm in algorithms + [\"GlobalNode\"]:\n",
    "        if len(enqueued_reqs_data_avg[algorithm]) == 0:\n",
    "            print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "            continue\n",
    "\n",
    "        avg = enqueued_reqs_data_avg[algorithm][\"enqueued_reqs_ratios_avg\"]\n",
    "        std = enqueued_reqs_data_avg[algorithm][\"enqueued_reqs_ratios_std\"]\n",
    "\n",
    "        ax.plot(iteration_coords_x, avg, label=algorithm)\n",
    "        ax.fill_between(iteration_coords_x, avg - std, avg + std, alpha=0.5)\n",
    "\n",
    "    ax.set_title(\"Average enqueued requests per episode (all agents)\")\n",
    "\n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Show 10% ticks.\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "\n",
    "\n",
    "make_avg_enqueued_reqs_plot_all_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Average enqueued requests per algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess additional data.\n",
    "enqueued_reqs_by_type_avg = {\"SAC\": {}, \"PPO\": {}, \"APL\": {}}\n",
    "algorithms = [\"SAC\", \"PPO\", \"APL\"]\n",
    "for algorithm in algorithms:\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms (and environment).\n",
    "        if algorithm in exp_dir.name and \"SingleDFaaS\" not in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "        continue\n",
    "\n",
    "    ratios_local, ratios_forward, ratios_reject = [], [], []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp_local = (\n",
    "            enqueued_reqs_data[exp][\"all\"][\"enqueued_reqs_local_avg\"]\n",
    "            / enqueued_reqs_data[exp][\"all\"][\"input_reqs_avg\"]\n",
    "        )\n",
    "        ratios_single_exp_forward = (\n",
    "            enqueued_reqs_data[exp][\"all\"][\"enqueued_reqs_forward_avg\"]\n",
    "            / enqueued_reqs_data[exp][\"all\"][\"input_reqs_avg\"]\n",
    "        )\n",
    "        ratios_single_exp_reject = (\n",
    "            enqueued_reqs_data[exp][\"all\"][\"enqueued_reqs_reject_avg\"]\n",
    "            / enqueued_reqs_data[exp][\"all\"][\"input_reqs_avg\"]\n",
    "        )\n",
    "\n",
    "        ratios_local.append(ratios_single_exp_local)\n",
    "        ratios_forward.append(ratios_single_exp_forward)\n",
    "        ratios_reject.append(ratios_single_exp_reject)\n",
    "    ratios_local = np.array(ratios_local)\n",
    "    ratios_forward = np.array(ratios_forward)\n",
    "    ratios_reject = np.array(ratios_reject)\n",
    "\n",
    "    avg_local = np.average(ratios_local, axis=0)\n",
    "    std_local = np.std(ratios_local, axis=0)\n",
    "\n",
    "    avg_forward = np.average(ratios_forward, axis=0)\n",
    "    std_forward = np.std(ratios_forward, axis=0)\n",
    "\n",
    "    avg_reject = np.average(ratios_reject, axis=0)\n",
    "    std_reject = np.std(ratios_reject, axis=0)\n",
    "\n",
    "    enqueued_reqs_by_type_avg[algorithm][\"Local\"] = {\"avg\": avg_local, \"std\": std_local}\n",
    "    enqueued_reqs_by_type_avg[algorithm][\"Forwarded\"] = {\n",
    "        \"avg\": avg_forward,\n",
    "        \"std\": std_forward,\n",
    "    }\n",
    "    enqueued_reqs_by_type_avg[algorithm][\"Rejected\"] = {\n",
    "        \"avg\": avg_reject,\n",
    "        \"std\": std_reject,\n",
    "    }\n",
    "\n",
    "    print(f\"Algorithm {algorithm} done with {len(experiments)} experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_avg_enqueued_reqs_plot_by_type(algorithm):\n",
    "    if len(enqueued_reqs_by_type_avg[algorithm]) == 0:\n",
    "        print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "        return\n",
    "\n",
    "    plt.close(fig=f\"avg_enqueued_by_type_{algorithm}\")\n",
    "    fig = plt.figure(\n",
    "        num=f\"avg_enqueued_by_type_{algorithm}\", layout=\"constrained\", figsize=(7.68, 4)\n",
    "    )\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    iteration_coords_x = np.linspace(start=1, stop=300, num=300)\n",
    "\n",
    "    for reqs_type in [\"Local\", \"Forwarded\", \"Rejected\"]:\n",
    "        avg = enqueued_reqs_by_type_avg[algorithm][reqs_type][\"avg\"]\n",
    "        std = enqueued_reqs_by_type_avg[algorithm][reqs_type][\"std\"]\n",
    "\n",
    "        ax.plot(iteration_coords_x, avg, label=reqs_type)\n",
    "        ax.fill_between(iteration_coords_x, avg - std, avg + std, alpha=0.5)\n",
    "\n",
    "        if reqs_type == \"Rejected\":\n",
    "            avg_apl = enqueued_reqs_by_type_avg[\"APL\"][reqs_type][\"avg\"]\n",
    "            ax.plot(\n",
    "                iteration_coords_x,\n",
    "                avg_apl,\n",
    "                label=f\"{reqs_type} (APL)\",\n",
    "                color=\"green\",\n",
    "                linestyle=\"dotted\",\n",
    "                linewidth=3,\n",
    "            )\n",
    "\n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0, decimals=0))\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "    data = enqueued_reqs_data  # Alias for better readability.\n",
    "\n",
    "    # Save also the plot to disk as PDF.\n",
    "    path = Path(f\"plots/enqueued_requests_train_{algorithm}.pdf\")\n",
    "    fig.savefig(path)\n",
    "    print(f\"Figure saved to: {path.as_posix()!r}\")\n",
    "\n",
    "\n",
    "make_avg_enqueued_reqs_plot_by_type(\"SAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_avg_enqueued_reqs_plot_by_type(\"PPO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Processed requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for processed requests.\n",
    "\n",
    "\n",
    "def get_processed_requests_data_upperbound(iters):\n",
    "    iterations = len(iters)\n",
    "    data = {\"input_reqs\": np.empty(iterations), \"processed_reqs\": np.empty(iterations)}\n",
    "\n",
    "    # Scan each iteration.\n",
    "    for iter_idx in range(iterations):\n",
    "        iter_data = iters[iter_idx][\"env_runners\"]\n",
    "\n",
    "        episodes = iter_data[\"episodes_this_iter\"]\n",
    "        input_reqs_iter = np.empty(episodes)\n",
    "        processed_local_iter = np.empty(episodes)\n",
    "\n",
    "        # Iterate the episodes.\n",
    "        for epi_idx in range(episodes):\n",
    "            input_reqs = np.sum(\n",
    "                iter_data[\"hist_stats\"][\"observation_input_requests\"][epi_idx]\n",
    "            )\n",
    "            processed_local = np.sum(\n",
    "                iter_data[\"hist_stats\"][\"processed_local\"][epi_idx]\n",
    "            )\n",
    "\n",
    "            input_reqs_iter[epi_idx] = input_reqs\n",
    "            processed_local_iter[epi_idx] = processed_local\n",
    "\n",
    "        # Update iteration data (average the episodes values).\n",
    "        data[\"input_reqs\"][iter_idx] = np.average(input_reqs_iter)\n",
    "        data[\"processed_reqs\"][iter_idx] = np.average(processed_local_iter)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_processed_requests_data_episode(iter_data, epi_idx, env):\n",
    "    episodes = iter_data[\"env_runners\"][\"episodes_this_iter\"]\n",
    "    iter_data = iter_data[\"env_runners\"][\"hist_stats\"]\n",
    "\n",
    "    data = defaultdict(lambda: defaultdict())\n",
    "    (\n",
    "        data[\"all\"][\"processed_reqs\"],\n",
    "        data[\"all\"][\"input_reqs\"],\n",
    "        data[\"all\"][\"processed_forwarded_reqs\"],\n",
    "    ) = (0, 0, 0)\n",
    "    for agent in env.agents:\n",
    "        processed_reqs = np.sum(iter_data[\"processed_local\"][epi_idx][agent])\n",
    "        input_reqs = np.sum(iter_data[\"observation_input_requests\"][epi_idx][agent])\n",
    "\n",
    "        try:\n",
    "            processed_forward = np.sum(\n",
    "                iter_data[\"processed_local_forward\"][epi_idx][agent]\n",
    "            )\n",
    "        except (KeyError, IndexError):\n",
    "            # May be missing if the agent did not receive any forwarded request.\n",
    "            processed_forward = 0\n",
    "\n",
    "        data[agent][\"processed_reqs\"] = processed_reqs\n",
    "        data[agent][\"input_reqs\"] = input_reqs\n",
    "        data[agent][\"processed_forwarded_reqs\"] = processed_forward\n",
    "        data[\"all\"][\"processed_reqs\"] += processed_reqs\n",
    "        data[\"all\"][\"input_reqs\"] += input_reqs\n",
    "        data[\"all\"][\"processed_forwarded_reqs\"] += processed_forward\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_processed_requests_data(iter_data):\n",
    "    #  is a disctionary with three levels of depth (experiment, iteration, metrics).\n",
    "    final_data = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "\n",
    "    for exp_dir, iters in iter_data.items():\n",
    "        env = base.get_env(exp_dir)\n",
    "        if env.__class__ == dfaas_upperbound.SingleDFaaS:\n",
    "            # The GlobalNode data extraction is different from the normal flow.\n",
    "            final_data[exp_dir] = get_processed_requests_data_upperbound(iters)\n",
    "            continue\n",
    "\n",
    "        agents = env.agents\n",
    "        iterations = len(iters)\n",
    "\n",
    "        # Create the portion of the dictionary for this experiment that\n",
    "        # contains the average values of the metrics for each iteration.\n",
    "        for agent in [\"all\"] + env.agents:\n",
    "            for key in [\"input_reqs\", \"processed_reqs\", \"processed_forwarded_reqs\"]:\n",
    "                final_data[exp_dir][agent][key] = np.empty(iterations)\n",
    "\n",
    "        # For each iteration, calculate the metrics for each episode played,\n",
    "        # then average the values for the number of episodes of that iteration.\n",
    "        for iter_idx in range(iterations):\n",
    "            episodes = iters[iter_idx][\"env_runners\"][\"episodes_this_iter\"]\n",
    "\n",
    "            # Create the data dictionary that contains the metrics for each\n",
    "            # episode in this iteration.\n",
    "            data = defaultdict(lambda: defaultdict())\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                for key in [\"input_reqs\", \"processed_reqs\", \"processed_forwarded_reqs\"]:\n",
    "                    data[agent][key] = np.empty(episodes, dtype=np.int32)\n",
    "\n",
    "            # Iterate the episodes.\n",
    "            for epi_idx in range(episodes):\n",
    "                data_epi = get_processed_requests_data_episode(\n",
    "                    iters[iter_idx], epi_idx, env\n",
    "                )\n",
    "\n",
    "                for agent in [\"all\"] + env.agents:\n",
    "                    for key in [\n",
    "                        \"input_reqs\",\n",
    "                        \"processed_reqs\",\n",
    "                        \"processed_forwarded_reqs\",\n",
    "                    ]:\n",
    "                        data[agent][key][epi_idx] = data_epi[agent][key]\n",
    "\n",
    "            # Update iteration data.\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                for key in [\"input_reqs\", \"processed_reqs\", \"processed_forwarded_reqs\"]:\n",
    "                    final_data[exp_dir][agent][key][iter_idx] = np.average(\n",
    "                        data[agent][key]\n",
    "                    )\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "processed_reqs_data = get_processed_requests_data(raw_exp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess additional data.\n",
    "processed_reqs_data_avg = {\"SAC\": {}, \"PPO\": {}, \"APL\": {}, \"GlobalNode\": {}}\n",
    "algorithms = [\"SAC\", \"PPO\", \"APL\"]\n",
    "for algorithm in algorithms:\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms (and environment).\n",
    "        if algorithm in exp_dir.name and \"SingleDFaaS\" not in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "        continue\n",
    "\n",
    "    ratios = []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp = (\n",
    "            processed_reqs_data[exp][\"all\"][\"processed_reqs\"]\n",
    "            / processed_reqs_data[exp][\"all\"][\"input_reqs\"]\n",
    "        )\n",
    "\n",
    "        ratios.append(ratios_single_exp)\n",
    "    ratios = np.array(ratios)\n",
    "\n",
    "    avg = np.average(ratios, axis=0)\n",
    "    std = np.std(ratios, axis=0)\n",
    "\n",
    "    processed_reqs_data_avg[algorithm][\"processed_reqs_ratios_avg\"] = avg\n",
    "    processed_reqs_data_avg[algorithm][\"processed_reqs_ratios_std\"] = std\n",
    "\n",
    "    print(f\"Algorithm {algorithm} done with {len(experiments)} experiments\")\n",
    "\n",
    "\n",
    "# GlobalNode case is special.\n",
    "def upperbound_processed_request():\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms and environment.\n",
    "        if \"SingleDFaaS\" in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(\"WARN: Skipping GlobalNode, no experiments found!\")\n",
    "        return\n",
    "\n",
    "    ratios = []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp = (\n",
    "            processed_reqs_data[exp][\"processed_reqs\"]\n",
    "            / processed_reqs_data[exp][\"input_reqs\"]\n",
    "        )\n",
    "\n",
    "        ratios.append(ratios_single_exp)\n",
    "    ratios = np.array(ratios)\n",
    "\n",
    "    avg = np.average(ratios, axis=0)\n",
    "    std = np.std(ratios, axis=0)\n",
    "\n",
    "    processed_reqs_data_avg[\"GlobalNode\"][\"processed_reqs_ratios_avg\"] = avg\n",
    "    processed_reqs_data_avg[\"GlobalNode\"][\"processed_reqs_ratios_std\"] = std\n",
    "\n",
    "    print(f\"GlobalNode done with {len(experiments)} experiments\")\n",
    "\n",
    "\n",
    "upperbound_processed_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### All agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_avg_processed_reqs_plot_all_agents():\n",
    "    plt.close(fig=\"avg_processed_reqs_all_agents\")\n",
    "    fig = plt.figure(\n",
    "        num=\"avg_processed_reqs_all_agents\", layout=\"constrained\", figsize=(7.68, 5)\n",
    "    )\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    iteration_coords_x = np.linspace(start=1, stop=300, num=300)\n",
    "\n",
    "    for algorithm in algorithms + [\"GlobalNode\"]:\n",
    "        if len(processed_reqs_data_avg[algorithm]) == 0:\n",
    "            print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "            continue\n",
    "\n",
    "        avg = processed_reqs_data_avg[algorithm][\"processed_reqs_ratios_avg\"]\n",
    "        std = processed_reqs_data_avg[algorithm][\"processed_reqs_ratios_std\"]\n",
    "\n",
    "        ax.plot(iteration_coords_x, avg, label=algorithm)\n",
    "        ax.fill_between(iteration_coords_x, avg - std, avg + std, alpha=0.5)\n",
    "\n",
    "    # ax.set_title(\"Average processed requests per episode (all agents)\")\n",
    "\n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Show 10% ticks.\n",
    "    # figsize=(25, 6)ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "\n",
    "    path = Path(f\"plots/processed_requests_train.pdf\")\n",
    "    fig.savefig(path)\n",
    "    print(f\"Figure saved to: {path.as_posix()!r}\")\n",
    "\n",
    "\n",
    "make_avg_processed_reqs_plot_all_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Queue size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for queue.\n",
    "\n",
    "\n",
    "def get_queue_data_upperbound(env, iters):\n",
    "    iterations = len(iters)\n",
    "    data = {\n",
    "        \"queue_size\": np.empty(iterations),\n",
    "        \"queue_full\": np.empty(iterations),\n",
    "        \"queue_size_std\": np.empty(iterations),\n",
    "    }\n",
    "\n",
    "    # Scan each iteration.\n",
    "    for iter_idx in range(iterations):\n",
    "        iter_data = iters[iter_idx][\"env_runners\"]\n",
    "\n",
    "        episodes = iter_data[\"episodes_this_iter\"]\n",
    "\n",
    "        queue_size = np.empty(episodes)\n",
    "        queue_size_std = np.empty(episodes)\n",
    "        queue_full = np.empty(episodes)\n",
    "\n",
    "        # Iterate the episodes.\n",
    "        for epi_idx in range(episodes):\n",
    "            queue = np.array(iter_data[\"hist_stats\"][\"queue_size\"][epi_idx])\n",
    "\n",
    "            queue_size[epi_idx] = np.mean(queue)\n",
    "            queue_size_std[epi_idx] = np.std(queue)\n",
    "            queue_full[epi_idx] = np.where(queue == env.queue_capacity)[0].size\n",
    "\n",
    "        # Update iteration data (average the episodes values).\n",
    "        data[\"queue_size\"][iter_idx] = np.average(queue_size)\n",
    "        data[\"queue_size_std\"][iter_idx] = np.average(queue_size_std)\n",
    "        data[\"queue_full\"][iter_idx] = np.average(queue_full)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_queue_data(iter_data):\n",
    "    #  is a disctionary with three levels of depth (experiment, iteration, metrics).\n",
    "    final_data = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "\n",
    "    for exp_dir, iters in iter_data.items():\n",
    "        env = base.get_env(exp_dir)\n",
    "        if env.__class__ == dfaas_upperbound.SingleDFaaS:\n",
    "            # The GlobalNode data extraction is different from the normal flow.\n",
    "            final_data[exp_dir] = get_queue_data_upperbound(env, iters)\n",
    "            continue\n",
    "\n",
    "        iterations = len(iters)\n",
    "\n",
    "        # Keys of the dictionary for each agent.\n",
    "        metrics = [\"queue_size_mean\", \"queue_size_std\", \"queue_full\"]\n",
    "\n",
    "        # Create the portion of the dictionary for this experiment that\n",
    "        # contains the average values of the metrics for each iteration.\n",
    "        for agent in [\"all\"] + env.agents:\n",
    "            for metric in metrics:\n",
    "                final_data[exp_dir][agent][metric] = np.empty(iterations)\n",
    "\n",
    "        # For each iteration, calculate the metrics for each episode played,\n",
    "        # then average the values for the number of episodes of that iteration.\n",
    "        for iter_idx in range(iterations):\n",
    "            episodes = iters[iter_idx][\"env_runners\"][\"episodes_this_iter\"]\n",
    "            hist_stats = iters[iter_idx][\"env_runners\"][\"hist_stats\"]\n",
    "\n",
    "            # Temporary dictionary for each iteration.\n",
    "            epi_data = defaultdict(lambda: defaultdict())\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                for metric in metrics:\n",
    "                    epi_data[agent][metric] = np.empty(episodes)\n",
    "\n",
    "            # Iterate the episodes.\n",
    "            for epi_idx in range(episodes):\n",
    "                queue_all = np.empty(0)\n",
    "\n",
    "                for agent in env.agents:\n",
    "                    queue = np.array(hist_stats[\"queue_size\"][epi_idx][agent])\n",
    "                    queue_all = np.concatenate([queue_all, queue])\n",
    "\n",
    "                    epi_data[agent][\"queue_size_mean\"][epi_idx] = np.mean(queue)\n",
    "                    epi_data[agent][\"queue_size_std\"][epi_idx] = np.std(queue)\n",
    "\n",
    "                    # Count the number of occurencies where queue is full\n",
    "                    epi_data[agent][\"queue_full\"][epi_idx] = np.where(\n",
    "                        queue == env.queue_capacity\n",
    "                    )[0].size\n",
    "\n",
    "                epi_data[\"all\"][\"queue_size_mean\"][epi_idx] = np.mean(queue_all)\n",
    "                epi_data[\"all\"][\"queue_size_std\"][epi_idx] = np.std(queue_all)\n",
    "                epi_data[\"all\"][\"queue_full\"][epi_idx] = np.where(\n",
    "                    queue == env.queue_capacity\n",
    "                )[0].size\n",
    "\n",
    "            # Update iteration data.\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                for metric in metrics:\n",
    "                    mean = np.mean(epi_data[agent][metric])\n",
    "                    final_data[exp_dir][agent][metric][iter_idx] = mean\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "queue_data = get_queue_data(raw_exp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Average queue size per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess additional data.\n",
    "queue_size_avg = {\"SAC\": {}, \"PPO\": {}, \"APL\": {}}\n",
    "algorithms = [\"SAC\", \"PPO\", \"APL\"]\n",
    "for algorithm in algorithms:\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms (and environment).\n",
    "        if algorithm in exp_dir.name and \"SingleDFaaS\" not in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "        continue\n",
    "\n",
    "    ratios = []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp = (\n",
    "            queue_data[exp][\"all\"][\"queue_size_mean\"] / env.queue_capacity\n",
    "        )\n",
    "\n",
    "        ratios.append(ratios_single_exp)\n",
    "    ratios = np.array(ratios)\n",
    "\n",
    "    avg = np.average(ratios, axis=0)\n",
    "    std = np.std(ratios, axis=0)\n",
    "\n",
    "    queue_size_avg[algorithm][\"queue_size_ratios_avg\"] = avg\n",
    "    queue_size_avg[algorithm][\"queue_size_ratios_std\"] = std\n",
    "\n",
    "    print(f\"Algorithm {algorithm} done with {len(experiments)} experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### All agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_avg_queue_size_plot_all_agents():\n",
    "    plt.close(fig=\"avg_queue_size_all_agents\")\n",
    "    fig = plt.figure(\n",
    "        num=\"avg_queue_size_all_agents\", layout=\"constrained\", figsize=(7.68, 4)\n",
    "    )\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    iteration_coords_x = np.linspace(start=1, stop=300, num=300)\n",
    "\n",
    "    for algorithm in algorithms:\n",
    "        if len(enqueued_reqs_data_avg[algorithm]) == 0:\n",
    "            print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "            continue\n",
    "\n",
    "        avg = queue_size_avg[algorithm][\"queue_size_ratios_avg\"]\n",
    "        std = queue_size_avg[algorithm][\"queue_size_ratios_std\"]\n",
    "\n",
    "        ax.plot(iteration_coords_x, avg, label=algorithm)\n",
    "        ax.fill_between(iteration_coords_x, avg - std, avg + std, alpha=0.5)\n",
    "\n",
    "    # ax.set_title(\"Average queue size per episode (all agents)\")\n",
    "\n",
    "    ax.set_ylabel(\"Requests in queue\")\n",
    "    ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Show 10% ticks.\n",
    "    # ax.set_ylim(0, 0.5)\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "\n",
    "    path = Path(f\"plots/queue_size_train.pdf\")\n",
    "    fig.savefig(path)\n",
    "    print(f\"Figure saved to: {path.as_posix()!r}\")\n",
    "\n",
    "\n",
    "make_avg_queue_size_plot_all_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Experiment loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dir = Path(\"../results/paise2025_2\")\n",
    "\n",
    "exps_dir = []\n",
    "for exp in prefix_dir.iterdir():\n",
    "    exps_dir.append(exp)\n",
    "\n",
    "# DEBUG\n",
    "# exps_dir = [prefix_dir / \"DFAAS-MA_2025-02-13_02-11-18_PPO_45\"]\n",
    "\n",
    "assert len(exps_dir) > 0, \"must select at least one experiment\"\n",
    "\n",
    "# Preload the data (evaluation.json file) for all selected experiments.\n",
    "raw_eval_data = {}\n",
    "for exp_dir in exps_dir:\n",
    "    raw_eval_data[exp_dir] = dfaas_utils.parse_result_file(exp_dir / \"evaluation.json\")\n",
    "\n",
    "# Create the reference environment based on DFaaS.\n",
    "for exp_dir in exps_dir:\n",
    "    env = base.get_env(exp_dir)\n",
    "    if env.__class__ == dfaas_env.DFaaS:\n",
    "        break\n",
    "\n",
    "# At least one experiment must be of type DFaaS. SingleDFaaS is used only as\n",
    "# reference.\n",
    "assert env.__class__ == dfaas_env.DFaaS, f\"{env.__class__}\"\n",
    "\n",
    "print(\"Selected experiments:\")\n",
    "for exp_dir in exps_dir:\n",
    "    print(f\"  - {exp_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Enqueued requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for processed requests.\n",
    "\n",
    "\n",
    "def get_enqueued_requests_data_globalnode_eval(evals):\n",
    "    episodes = evals[0][\"env_runners\"][\"num_episodes\"]\n",
    "    eval_data = evals[0][\"env_runners\"][\"hist_stats\"]\n",
    "    assert episodes > 0\n",
    "\n",
    "    data = {}\n",
    "    data[\"input_reqs\"] = np.zeros(episodes)\n",
    "    data[\"enqueued_reqs_local\"] = np.zeros(episodes)\n",
    "    data[\"enqueued_reqs_reject\"] = np.zeros(episodes)\n",
    "\n",
    "    # Iterate the episodes.\n",
    "    for epi_idx in range(episodes):\n",
    "        input_reqs = np.sum(eval_data[\"observation_input_requests\"][epi_idx])\n",
    "\n",
    "        # Calculate local, queued, or directly processed requests. Note that the\n",
    "        # rejections must be subtracted!\n",
    "        local_reqs = np.array(eval_data[\"action_local\"][epi_idx])\n",
    "        local_rejects = np.array(eval_data[\"local_rejects_queue_full\"][epi_idx])\n",
    "        real_local_reqs = np.sum(local_reqs - local_rejects)\n",
    "\n",
    "        real_rejected_reqs = np.sum(local_rejects)\n",
    "\n",
    "        assert np.all(real_local_reqs + real_rejected_reqs == input_reqs)\n",
    "\n",
    "        data[\"input_reqs\"][epi_idx] = input_reqs\n",
    "        data[\"enqueued_reqs_local\"][epi_idx] = real_local_reqs\n",
    "        data[\"enqueued_reqs_reject\"] = real_rejected_reqs\n",
    "\n",
    "    # Update final data.\n",
    "    final_data = {}\n",
    "    final_data[\"input_reqs_avg\"] = np.average(data[\"input_reqs\"])\n",
    "    final_data[\"enqueued_reqs_local_avg\"] = np.average(data[\"enqueued_reqs_local\"])\n",
    "    final_data[\"enqueued_reqs_forward_avg\"] = 0\n",
    "    final_data[\"enqueued_reqs_reject_avg\"] = np.average(data[\"enqueued_reqs_reject\"])\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "def get_enqueued_requests_data_eval(raw_eval_data):\n",
    "    # (experiment, metrics).\n",
    "    final_data = defaultdict(lambda: defaultdict())\n",
    "\n",
    "    for exp_dir, evals in raw_eval_data.items():\n",
    "        env = base.get_env(exp_dir)\n",
    "        if env.__class__ == dfaas_upperbound.SingleDFaaS:\n",
    "            # The GlobalNode data extraction is different from the normal flow.\n",
    "            final_data[exp_dir] = get_enqueued_requests_data_globalnode_eval(evals)\n",
    "            continue\n",
    "\n",
    "        episodes = evals[0][\"env_runners\"][\"num_episodes\"]\n",
    "        eval_data = evals[0][\"env_runners\"][\"hist_stats\"]\n",
    "        assert episodes > 0\n",
    "\n",
    "        data = {}\n",
    "        data[\"input_reqs\"] = np.zeros(episodes)\n",
    "        data[\"enqueued_reqs_local\"] = np.zeros(episodes)\n",
    "        data[\"enqueued_reqs_forward\"] = np.zeros(episodes)\n",
    "        data[\"enqueued_reqs_reject\"] = np.zeros(episodes)\n",
    "\n",
    "        # Iterate the episodes.\n",
    "        for epi_idx in range(episodes):\n",
    "            for agent in env.agents:\n",
    "                input_reqs = np.sum(\n",
    "                    eval_data[\"observation_input_requests\"][epi_idx][agent]\n",
    "                )\n",
    "\n",
    "                # Calculate local, queued, or directly processed requests. Note that the\n",
    "                # rejections must be subtracted!\n",
    "                local_reqs = np.array(eval_data[\"action_local\"][epi_idx][agent])\n",
    "                local_rejects = np.array(\n",
    "                    eval_data[\"local_rejects_queue_full\"][epi_idx][agent]\n",
    "                )\n",
    "                real_local_reqs = np.sum(local_reqs - local_rejects)\n",
    "\n",
    "                # Same for forwarded requests.\n",
    "                forwarded_reqs = np.array(eval_data[\"action_forward\"][epi_idx][agent])\n",
    "                forwarded_rejects = np.array(\n",
    "                    eval_data[\"forward_rejects\"][epi_idx][agent]\n",
    "                )\n",
    "                real_forwarded_reqs = np.sum(forwarded_reqs - forwarded_rejects)\n",
    "\n",
    "                rejected_reqs = np.array(eval_data[\"action_reject\"][epi_idx][agent])\n",
    "                real_rejected_reqs = np.sum(\n",
    "                    rejected_reqs + local_rejects + forwarded_rejects\n",
    "                )\n",
    "\n",
    "                assert np.all(\n",
    "                    real_local_reqs + real_forwarded_reqs + real_rejected_reqs\n",
    "                    == input_reqs\n",
    "                )\n",
    "\n",
    "                data[\"input_reqs\"][epi_idx] += input_reqs\n",
    "                data[\"enqueued_reqs_local\"][epi_idx] += real_local_reqs\n",
    "                data[\"enqueued_reqs_forward\"][epi_idx] += real_forwarded_reqs\n",
    "                data[\"enqueued_reqs_reject\"][epi_idx] += real_rejected_reqs\n",
    "\n",
    "        # Update final data.\n",
    "        final_data[exp_dir][\"input_reqs_avg\"] = np.average(data[\"input_reqs\"])\n",
    "        final_data[exp_dir][\"enqueued_reqs_local_avg\"] = np.average(\n",
    "            data[\"enqueued_reqs_local\"]\n",
    "        )\n",
    "        final_data[exp_dir][\"enqueued_reqs_forward_avg\"] = np.average(\n",
    "            data[\"enqueued_reqs_forward\"]\n",
    "        )\n",
    "        final_data[exp_dir][\"enqueued_reqs_reject_avg\"] = np.average(\n",
    "            data[\"enqueued_reqs_reject\"]\n",
    "        )\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "enqueued_reqs_data = get_enqueued_requests_data_eval(raw_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess additional data.\n",
    "enqueued_reqs_by_type_avg = {\"SAC\": {}, \"PPO\": {}, \"APL\": {}, \"GlobalNode\": {}}\n",
    "algorithms = [\"SAC\", \"PPO\", \"APL\", \"GlobalNode\"]\n",
    "for algorithm in algorithms:\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms (and environment).\n",
    "        if algorithm == \"GlobalNode\" and \"SingleDFaaS\" in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "            continue\n",
    "        if algorithm in exp_dir.name and \"SingleDFaaS\" not in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "        continue\n",
    "\n",
    "    ratios_local, ratios_forward, ratios_reject = [], [], []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp_local = (\n",
    "            enqueued_reqs_data[exp][\"enqueued_reqs_local_avg\"]\n",
    "            / enqueued_reqs_data[exp][\"input_reqs_avg\"]\n",
    "        )\n",
    "        ratios_single_exp_forward = (\n",
    "            enqueued_reqs_data[exp][\"enqueued_reqs_forward_avg\"]\n",
    "            / enqueued_reqs_data[exp][\"input_reqs_avg\"]\n",
    "        )\n",
    "        ratios_single_exp_reject = (\n",
    "            enqueued_reqs_data[exp][\"enqueued_reqs_reject_avg\"]\n",
    "            / enqueued_reqs_data[exp][\"input_reqs_avg\"]\n",
    "        )\n",
    "\n",
    "        ratios_local.append(ratios_single_exp_local)\n",
    "        ratios_forward.append(ratios_single_exp_forward)\n",
    "        ratios_reject.append(ratios_single_exp_reject)\n",
    "    ratios_local = np.array(ratios_local)\n",
    "    ratios_forward = np.array(ratios_forward)\n",
    "    ratios_reject = np.array(ratios_reject)\n",
    "\n",
    "    avg_local = np.average(ratios_local, axis=0)\n",
    "    std_local = np.std(ratios_local, axis=0)\n",
    "\n",
    "    avg_forward = np.average(ratios_forward, axis=0)\n",
    "    std_forward = np.std(ratios_forward, axis=0)\n",
    "\n",
    "    avg_reject = np.average(ratios_reject, axis=0)\n",
    "    std_reject = np.std(ratios_reject, axis=0)\n",
    "\n",
    "    enqueued_reqs_by_type_avg[algorithm][\"Local\"] = {\"avg\": avg_local, \"std\": std_local}\n",
    "    enqueued_reqs_by_type_avg[algorithm][\"Forwarded\"] = {\n",
    "        \"avg\": avg_forward,\n",
    "        \"std\": std_forward,\n",
    "    }\n",
    "    enqueued_reqs_by_type_avg[algorithm][\"Rejected\"] = {\n",
    "        \"avg\": avg_reject,\n",
    "        \"std\": std_reject,\n",
    "    }\n",
    "\n",
    "    print(f\"Algorithm {algorithm} done with {len(experiments)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in enqueued_reqs_by_type_avg.keys():\n",
    "    print(\"Algorithm:\", algorithm)\n",
    "    for reqs_type in enqueued_reqs_by_type_avg[algorithm].keys():\n",
    "        print(\n",
    "            f\"    {reqs_type}: {enqueued_reqs_by_type_avg[algorithm][reqs_type]['avg']*100}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
