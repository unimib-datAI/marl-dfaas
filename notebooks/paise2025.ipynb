{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PAISE 2025 Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports.\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib widget\n",
    "import base\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import ipywidgets\n",
    "\n",
    "import dfaas_env\n",
    "import dfaas_utils\n",
    "import dfaas_upperbound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Experiment loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_dir = Path(\"../results/paise2025\")\n",
    "\n",
    "exps_dir = []\n",
    "for exp in prefix_dir.iterdir():\n",
    "    exps_dir.append(exp)\n",
    "\n",
    "assert len(exps_dir) > 0, \"must select at least one experiment\"\n",
    "\n",
    "# Preload the data (result.json file) for all selected experiments.\n",
    "raw_exp_data = {}\n",
    "for exp_dir in exps_dir:\n",
    "    raw_exp_data[exp_dir] = dfaas_utils.parse_result_file(exp_dir / \"result.json\")\n",
    "\n",
    "# Create the reference environment based on DFaaS.\n",
    "for exp_dir in exps_dir:\n",
    "    env = base.get_env(exp_dir)\n",
    "    if env.__class__ == dfaas_env.DFaaS:\n",
    "        break\n",
    "\n",
    "# At least one experiment must be of type DFaaS. SingleDFaaS is used only as\n",
    "# reference.\n",
    "assert env.__class__ == dfaas_env.DFaaS, f\"{env.__class__}\"\n",
    "\n",
    "print(\"Selected experiments:\")\n",
    "for exp_dir in exps_dir:\n",
    "    print(f\"  - {exp_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Enqueued requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions for processed requests.\n",
    "\n",
    "\n",
    "def get_enqueued_requests_data_upperbound(iters):\n",
    "    iterations = len(iters)\n",
    "    final_data = {}\n",
    "    final_data[\"input_reqs_avg\"] = np.empty(iterations)\n",
    "    final_data[\"enqueued_reqs_local_avg\"] = np.empty(iterations)\n",
    "    final_data[\"enqueued_reqs_forward_avg\"] = np.empty(iterations)\n",
    "\n",
    "    # For each iteration, calculate the metrics for each episode played,\n",
    "    # then average the values for the number of episodes of that iteration.\n",
    "    for iter_idx in range(iterations):\n",
    "        episodes = iters[iter_idx][\"env_runners\"][\"episodes_this_iter\"]\n",
    "        iter_data = iters[iter_idx][\"env_runners\"][\"hist_stats\"]\n",
    "\n",
    "        # Create the data dictionary that contains the metrics for each\n",
    "        # episode in this iteration.\n",
    "        data = {}\n",
    "        data[\"input_reqs\"] = np.empty(episodes, dtype=np.int32)\n",
    "        data[\"enqueued_reqs_local\"] = np.empty(episodes, dtype=np.int32)\n",
    "        data[\"enqueued_reqs_forward\"] = np.empty(episodes, dtype=np.int32)\n",
    "\n",
    "        # Iterate the episodes.\n",
    "        for epi_idx in range(episodes):\n",
    "            input_reqs = np.sum(iter_data[\"observation_input_requests\"][epi_idx])\n",
    "\n",
    "            # Calculate local, queued, or directly processed requests. Note that the\n",
    "            # rejections must be subtracted!\n",
    "            local_reqs = np.array(iter_data[\"action_local\"][epi_idx])\n",
    "            local_rejects = np.array(iter_data[\"local_rejects_queue_full\"][epi_idx])\n",
    "            real_local_reqs = np.sum(local_reqs - local_rejects)\n",
    "\n",
    "            data[\"input_reqs\"][epi_idx] = input_reqs\n",
    "            data[\"enqueued_reqs_local\"][epi_idx] = real_local_reqs\n",
    "\n",
    "        # Update iteration data.\n",
    "        final_data[\"input_reqs_avg\"][iter_idx] = np.average(data[\"input_reqs\"])\n",
    "        final_data[\"enqueued_reqs_local_avg\"][iter_idx] = np.average(\n",
    "            data[\"enqueued_reqs_local\"]\n",
    "        )\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "def get_enqueued_requests_data(iter_data):\n",
    "    # (experiment, iteration, metrics).\n",
    "    final_data = defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "\n",
    "    for exp_dir, iters in iter_data.items():\n",
    "        env = base.get_env(exp_dir)\n",
    "        if env.__class__ == dfaas_upperbound.SingleDFaaS:\n",
    "            # The upperbound data extraction is different from the normal flow.\n",
    "            final_data[exp_dir] = get_enqueued_requests_data_upperbound(iters)\n",
    "            continue\n",
    "\n",
    "        iterations = len(iters)\n",
    "\n",
    "        # Create the portion of the dictionary for this experiment that\n",
    "        # contains the average values of the metrics for each iteration.\n",
    "        for agent in [\"all\"] + env.agents:\n",
    "            final_data[exp_dir][agent][\"input_reqs_avg\"] = np.empty(iterations)\n",
    "            final_data[exp_dir][agent][\"enqueued_reqs_local_avg\"] = np.empty(iterations)\n",
    "            final_data[exp_dir][agent][\"enqueued_reqs_forward_avg\"] = np.empty(\n",
    "                iterations\n",
    "            )\n",
    "\n",
    "        # For each iteration, calculate the metrics for each episode played,\n",
    "        # then average the values for the number of episodes of that iteration.\n",
    "        for iter_idx in range(iterations):\n",
    "            episodes = iters[iter_idx][\"env_runners\"][\"episodes_this_iter\"]\n",
    "            iter_data = iters[iter_idx][\"env_runners\"][\"hist_stats\"]\n",
    "\n",
    "            # Create the data dictionary that contains the metrics for each\n",
    "            # episode in this iteration.\n",
    "            data = defaultdict(lambda: defaultdict())\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                data[agent][\"input_reqs\"] = np.zeros(episodes, dtype=np.int32)\n",
    "                data[agent][\"enqueued_reqs_local\"] = np.zeros(episodes, dtype=np.int32)\n",
    "                data[agent][\"enqueued_reqs_forward\"] = np.zeros(\n",
    "                    episodes, dtype=np.int32\n",
    "                )\n",
    "\n",
    "            # Iterate the episodes.\n",
    "            for epi_idx in range(episodes):\n",
    "                for agent in env.agents:\n",
    "                    input_reqs = np.sum(\n",
    "                        iter_data[\"observation_input_requests\"][epi_idx][agent]\n",
    "                    )\n",
    "\n",
    "                    # Calculate local, queued, or directly processed requests. Note that the\n",
    "                    # rejections must be subtracted!\n",
    "                    local_reqs = np.array(iter_data[\"action_local\"][epi_idx][agent])\n",
    "                    local_rejects = np.array(\n",
    "                        iter_data[\"local_rejects_queue_full\"][epi_idx][agent]\n",
    "                    )\n",
    "                    real_local_reqs = np.sum(local_reqs - local_rejects)\n",
    "\n",
    "                    # Same for forwarded requests.\n",
    "                    forwarded_reqs = np.array(\n",
    "                        iter_data[\"action_forward\"][epi_idx][agent]\n",
    "                    )\n",
    "                    forwarded_rejects = np.array(\n",
    "                        iter_data[\"forward_rejects\"][epi_idx][agent]\n",
    "                    )\n",
    "                    real_forwarded_reqs = np.sum(forwarded_reqs - forwarded_rejects)\n",
    "\n",
    "                    data[agent][\"input_reqs\"][epi_idx] = input_reqs\n",
    "                    data[agent][\"enqueued_reqs_local\"][epi_idx] = real_local_reqs\n",
    "                    data[agent][\"enqueued_reqs_forward\"][epi_idx] = real_forwarded_reqs\n",
    "                    data[\"all\"][\"input_reqs\"][epi_idx] += input_reqs\n",
    "                    data[\"all\"][\"enqueued_reqs_local\"][epi_idx] += real_local_reqs\n",
    "                    data[\"all\"][\"enqueued_reqs_forward\"][epi_idx] += real_forwarded_reqs\n",
    "\n",
    "            # Update iteration data.\n",
    "            for agent in [\"all\"] + env.agents:\n",
    "                final_data[exp_dir][agent][\"input_reqs_avg\"][iter_idx] = np.average(\n",
    "                    data[agent][\"input_reqs\"]\n",
    "                )\n",
    "                final_data[exp_dir][agent][\"enqueued_reqs_local_avg\"][iter_idx] = (\n",
    "                    np.average(data[agent][\"enqueued_reqs_local\"])\n",
    "                )\n",
    "                final_data[exp_dir][agent][\"enqueued_reqs_forward_avg\"][iter_idx] = (\n",
    "                    np.average(data[agent][\"enqueued_reqs_forward\"])\n",
    "                )\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n",
    "enqueued_reqs_data = get_enqueued_requests_data(raw_exp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess additional data.\n",
    "enqueued_reqs_data_avg = {\"SAC\": {}, \"PPO\": {}, \"APL\": {}, \"Upperbound\": {}}\n",
    "algorithms = [\"SAC\", \"PPO\", \"APL\"]\n",
    "for algorithm in algorithms:\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms (and environment).\n",
    "        if algorithm in exp_dir.name and \"SingleDFaaS\" not in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "        continue\n",
    "\n",
    "    ratios = []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp = (\n",
    "            enqueued_reqs_data[exp][\"all\"][\"enqueued_reqs_local_avg\"]\n",
    "            + enqueued_reqs_data[exp][\"all\"][\"enqueued_reqs_forward_avg\"]\n",
    "        ) / enqueued_reqs_data[exp][\"all\"][\"input_reqs_avg\"]\n",
    "\n",
    "        ratios.append(ratios_single_exp)\n",
    "    ratios = np.array(ratios)\n",
    "\n",
    "    avg = np.average(ratios, axis=0)\n",
    "    std = np.std(ratios, axis=0)\n",
    "\n",
    "    enqueued_reqs_data_avg[algorithm][\"enqueued_reqs_ratios_avg\"] = avg\n",
    "    enqueued_reqs_data_avg[algorithm][\"enqueued_reqs_ratios_std\"] = std\n",
    "\n",
    "    print(f\"Algorithm {algorithm} done with {len(experiments)} experiments\")\n",
    "\n",
    "\n",
    "# Upperbound case is special.\n",
    "def upperbound_enqueued_request():\n",
    "    experiments = []\n",
    "    for exp_dir in exps_dir:\n",
    "        # The experiment name contains the used algorithms and environment.\n",
    "        if \"SingleDFaaS\" in exp_dir.name:\n",
    "            experiments.append(exp_dir)\n",
    "\n",
    "    if len(experiments) == 0:\n",
    "        print(\"WARN: Skipping upperbound, no experiments found!\")\n",
    "        return\n",
    "\n",
    "    ratios = []\n",
    "    for exp in experiments:\n",
    "        ratios_single_exp = (\n",
    "            enqueued_reqs_data[exp][\"enqueued_reqs_local_avg\"]\n",
    "            / enqueued_reqs_data[exp][\"input_reqs_avg\"]\n",
    "        )\n",
    "\n",
    "        ratios.append(ratios_single_exp)\n",
    "    ratios = np.array(ratios)\n",
    "\n",
    "    avg = np.average(ratios, axis=0)\n",
    "    std = np.std(ratios, axis=0)\n",
    "\n",
    "    enqueued_reqs_data_avg[\"Upperbound\"][\"enqueued_reqs_ratios_avg\"] = avg\n",
    "    enqueued_reqs_data_avg[\"Upperbound\"][\"enqueued_reqs_ratios_std\"] = std\n",
    "\n",
    "    print(f\"Upperbound done with {len(experiments)} experiments\")\n",
    "\n",
    "\n",
    "upperbound_enqueued_request()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Average enqueued requests per episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### All agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_avg_enqueued_reqs_plot_all_agents():\n",
    "    plt.close(fig=\"avg_enqueued_reqs_all_agents\")\n",
    "    fig = plt.figure(num=\"avg_enqueued_reqs_all_agents\", layout=\"constrained\")\n",
    "    fig.canvas.header_visible = False\n",
    "    ax = fig.subplots()\n",
    "\n",
    "    iteration_coords_x = np.linspace(start=1, stop=300, num=300)\n",
    "\n",
    "    for algorithm in algorithms + [\"Upperbound\"]:\n",
    "        if len(enqueued_reqs_data_avg[algorithm]) == 0:\n",
    "            print(f\"WARN: Skipping algorithm {algorithm}, no experiments found!\")\n",
    "            continue\n",
    "\n",
    "        avg = enqueued_reqs_data_avg[algorithm][\"enqueued_reqs_ratios_avg\"]\n",
    "        std = enqueued_reqs_data_avg[algorithm][\"enqueued_reqs_ratios_std\"]\n",
    "\n",
    "        ax.plot(iteration_coords_x, avg, label=algorithm)\n",
    "        ax.fill_between(iteration_coords_x, avg - std, avg + std, alpha=0.5)\n",
    "\n",
    "    ax.set_title(\"Average enqueued requests per episode (all agents)\")\n",
    "\n",
    "    ax.set_ylabel(\"Requests\")\n",
    "    ax.yaxis.set_major_formatter(ticker.PercentFormatter(1.0))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Show 10% ticks.\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"both\")\n",
    "    ax.set_axisbelow(True)  # By default the axis is over the content.\n",
    "\n",
    "\n",
    "make_avg_enqueued_reqs_plot_all_agents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
